{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b31b42c",
   "metadata": {},
   "source": [
    "# EL-GY-9133 Machine Learning for Cyber-Security\n",
    "\n",
    "## Lab 2: E-mail Spam Filtering\n",
    "\n",
    "#### Name: Varuni Buereddy\n",
    "#### Net-ID: vb2386\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1a625",
   "metadata": {},
   "source": [
    "### Overview\n",
    "In this lab, you will design an e-mail spam filter using a Naïve Bayes and SVM based classification on the ling-spam dataset. You will explore the impact of feature selection and compare the performance of different variants of an NB classifier and also implement your own SVM based classifier. (Note: You may use the scikitt learn classifiers to only compare the accuracy of their model to yours).\n",
    "\n",
    "### Dataset\n",
    "The ling-spam corpus contains e-mails from the Linguist mailing list categorized as either legitimate or spam emails. The corpus is divided into four sub-folders that contain the same emails that are pre-processed with/without lemmatization and with/without stop-word removal. The e-mails in each sub-folder partitioned into 10 \"folds.\"\n",
    "In this lab, we will use the first 9 folds from the ling-spam corpus as training data, and the 10th fold as test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1486d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "157dbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = './lingspam_public/lemm_stop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82cf68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfolder = os.listdir(path_to_dataset)\n",
    "trainfolder.remove('part10')\n",
    "testfolder = 'part10'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "462cad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading from folder\n",
    "\n",
    "def load_from_folder(folder, email_texts, labels):\n",
    "    folder = os.path.join(path_to_dataset,folder)\n",
    "    files = [os.path.join(folder,f) for f in os.listdir(folder)]\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            for i,line in enumerate(f):\n",
    "                if(i==2): \n",
    "                    email_texts.append(line)\n",
    "        if(file.startswith(folder+'/spmsg')):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0337e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************Training dataset:**************\n",
      "Number of Spam Emails: 432\n",
      "Number of Legit Emails: 2170\n",
      "************Test dataset:**************\n",
      "Number of Spam Emails: 49\n",
      "Number of Legit Emails: 242\n"
     ]
    }
   ],
   "source": [
    "train_emails = []\n",
    "train_labels = []\n",
    "test_emails = []\n",
    "test_labels = []\n",
    "\n",
    "for folder in trainfolder:\n",
    "    load_from_folder(folder, train_emails, train_labels)\n",
    "    \n",
    "load_from_folder(testfolder, test_emails, test_labels)\n",
    "\n",
    "N_spam = sum(train_labels)\n",
    "N_spam_test = sum(test_labels)\n",
    "print(\"************Training dataset:**************\")\n",
    "print(f\"Number of Spam Emails: {N_spam}\")\n",
    "print(f\"Number of Legit Emails: {len(train_labels)-N_spam}\")\n",
    "\n",
    "print(\"************Test dataset:**************\")\n",
    "print(f\"Number of Spam Emails: {sum(test_labels)}\")\n",
    "print(f\"Number of Legit Emails: {len(test_labels)-N_spam_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b01ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "def remove_punctuation(test_str):\n",
    "    result = ''.join(filter(lambda x: x.isalpha() or x.isdigit() or x.isspace(), test_str))\n",
    "    return result\n",
    "\n",
    "def preprocessing(emails):\n",
    "    filtered_list = emails.copy()\n",
    "    for i in range(len(emails)):\n",
    "        filtered_list[i] = (remove_punctuation(emails[i]))\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68fa4243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_train = preprocessing(train_emails)\n",
    "processed_test = preprocessing(test_emails)\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "vec = vectorizer.fit_transform(processed_train)\n",
    "vocab = vectorizer.vocabulary_\n",
    "vocab = dict((v,k) for k,v in vocab.items())\n",
    "X_train = vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "259f66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_matrix(processed_train, X_train):\n",
    "    X_train_spam = []\n",
    "    X_train_legit = []\n",
    "    for i in range(len(processed_train)):\n",
    "        if train_labels[i]==1:\n",
    "            X_train_spam.append(X_train[i])\n",
    "\n",
    "        else:\n",
    "            X_train_legit.append(X_train[i])\n",
    "\n",
    "    feature_matrix = [np.sum(np.array(X_train_spam), axis = 0), np.sum(np.array(X_train_legit), axis = 0)]\n",
    "    return feature_matrix\n",
    "\n",
    "feature_matrix = get_feature_matrix(processed_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae014bc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{30088: 'language', 42231: 'remove', 21612: 'free', 31079: 'linguistic', 51231: 'university', 34232: 'money', 13401: 'click', 32550: 'market', 37609: 'our', 11637: 'business', 49505: 'today', 40475: 'product', 6564: 'advertise', 13938: 'company', 44672: 'sell', 31090: 'linguistics', 18989: 'english', 33714: 'million', 26245: 'income', 26984: 'internet', 15860: 'day', 23501: 'guarantee', 49231: 'thousand', 44013: 'save', 18074: 'easy', 234: '100', 37671: 'over', 10257: 'best', 40979: 'purchase', 53623: 'win', 12830: 'check', 11662: 'buy', 11534: 'bulk', 52980: 'want', 12220: 'cash', 17414: 'dollar', 14877: 'cost', 19789: 'every', 18254: 'edu', 32132: 'mailing', 44926: 'service', 13813: 'com', 54498: 'yourself', 31313: 'll', 38041: 'papers', 31074: 'linguist', 25224: 'hour', 25428: 'hundred', 49088: 'theory', 18053: 'earn', 40509: 'profit', 15442: 'customer', 15901: 'de', 6078: 'abstract', 47535: 'success', 21868: 'fun', 36915: 'offer', 34323: 'month', 54497: 'yours', 14236: 'conference', 41725: 'receive', 19774: 'ever', 53052: 'watch', 46423: 'speaker', 10913: 'bonus', 32119: 'mail', 17098: 'discussion', 15083: 'credit', 54776: 'zip', 24502: 'here', 38422: 'pay', 31279: 'live', 7370: 'amaze', 43716: 'sale', 48081: 'syntax', 27171: 'investment', 16340: 'department', 46871: 'start', 23170: 'grammar', 8009: 'anywhere', 49563: 'toll', 17682: 'dream', 25348: 'huge', 20894: 'financial', 44316: 'science', 15912: 'deadline', 6364: 'ad', 45581: 'simply', 47273: 'structure', 53183: 'week', 34023: 'mlm', 21705: 'friend', 37181: 'online', 35421: 'need', 52907: 'wait', 53921: 'workshop', 21678: 'fresh', 47329: 'study', 44501: 'security', 7559: 'analysis'}\n"
     ]
    }
   ],
   "source": [
    "No_of_features = 100\n",
    "def calculate_mutual_info(feature, feature_matrix, N, N_spam): \n",
    "    N11 = feature_matrix[0][feature]\n",
    "    N10 = feature_matrix[1][feature]\n",
    "    N01 = (N_spam - N11)\n",
    "    N00 = N - (N11+N01+N10)\n",
    "    N1dot = N11+N10\n",
    "    Ndot1 = N_spam\n",
    "    N0dot = N01+N00\n",
    "    Ndot0 = N-N_spam\n",
    "    keys = [N11, N10, N01, N00]\n",
    "    values = [N1dot*Ndot1, N1dot*Ndot0, N0dot*Ndot1, N0dot*Ndot0]\n",
    "    mi = 0\n",
    "    for i in range(4):\n",
    "        if keys[i]==0:\n",
    "            mi+=0\n",
    "        else:\n",
    "            mi+= (keys[i]/N)*np.log2(keys[i]*N/values[i])\n",
    "    return mi \n",
    "\n",
    "IG = []\n",
    "for i in range(len(vocab)):\n",
    "    IG.append(calculate_mutual_info(i, feature_matrix, len(train_labels), sum(train_labels)))\n",
    "    \n",
    "sorted_index = np.argsort(np.array(IG))[::-1][:No_of_features]\n",
    "extracted_features = {s: vocab[s] for s in sorted_index}\n",
    "print(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d4ac294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def mutual_info(vocab, feature_matrix, N, N_spam, no_of_features):\\n\\n    IG = []\\n    for i in range(len(vocab)):\\n        N11 = feature_matrix[0][i]\\n        N10 = feature_matrix[1][i]\\n        N01 = (N_spam - N11)\\n        N00 = N - (N11+N01+N10)\\n        N1dot = N11+N10\\n        Ndot1 = N_spam\\n        N0dot = N01+N00\\n        Ndot0 = N-N_spam\\n        keys = [N11, N10, N01, N00]\\n        values = [N1dot*Ndot1, N1dot*Ndot0, N0dot*Ndot1, N0dot*Ndot0]\\n        mi = 0\\n        for i in range(4):\\n            if keys[i]==0:\\n                mi+=0\\n            else:\\n                mi+= (keys[i]/N)*np.log2(keys[i]*N/values[i])\\n        \\n        IG.append(mi)\\n    sorted_index = np.argsort(np.array(IG))[::-1][:no_of_features]\\n    extracted_features = {s: vocab[s] for s in sorted_index}\\n    \\n    return extracted_features\\n    \\nextracted_features = mutual_info(vocab, feature_matrix, len(train_labels), sum(train_labels), 100)\\nprint(extracted_features)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def mutual_info(vocab, feature_matrix, N, N_spam, no_of_features):\n",
    "\n",
    "    IG = []\n",
    "    for i in range(len(vocab)):\n",
    "        N11 = feature_matrix[0][i]\n",
    "        N10 = feature_matrix[1][i]\n",
    "        N01 = (N_spam - N11)\n",
    "        N00 = N - (N11+N01+N10)\n",
    "        N1dot = N11+N10\n",
    "        Ndot1 = N_spam\n",
    "        N0dot = N01+N00\n",
    "        Ndot0 = N-N_spam\n",
    "        keys = [N11, N10, N01, N00]\n",
    "        values = [N1dot*Ndot1, N1dot*Ndot0, N0dot*Ndot1, N0dot*Ndot0]\n",
    "        mi = 0\n",
    "        for i in range(4):\n",
    "            if keys[i]==0:\n",
    "                mi+=0\n",
    "            else:\n",
    "                mi+= (keys[i]/N)*np.log2(keys[i]*N/values[i])\n",
    "        \n",
    "        IG.append(mi)\n",
    "    sorted_index = np.argsort(np.array(IG))[::-1][:no_of_features]\n",
    "    extracted_features = {s: vocab[s] for s in sorted_index}\n",
    "    \n",
    "    return extracted_features\n",
    "    \n",
    "extracted_features = mutual_info(vocab, feature_matrix, len(train_labels), sum(train_labels), 100)\n",
    "print(extracted_features)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba7a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## X, Y\n",
    "def BernoulliNBclassifier(X, feature_matrix, features, N, N_spam):\n",
    "    log_px_spam = 0\n",
    "    log_px_legit = 0\n",
    "    for i in features.keys():\n",
    "        #print(feature_matrix[0][i]+1)\n",
    "        p_is = (feature_matrix[0][i]+1)/(N_spam+2)\n",
    "        p_il = (feature_matrix[1][i]+1)/(N-N_spam+2)\n",
    "        if features[i] in X:\n",
    "            log_px_spam = log_px_spam+np.log(p_is)\n",
    "            log_px_legit = log_px_legit+np.log(p_il)\n",
    "            \n",
    "        else:\n",
    "            log_px_spam = log_px_spam+np.log(1-p_is)\n",
    "            log_px_legit = log_px_legit+np.log(1-p_il)\n",
    "            \n",
    "    log_p_spam = np.log(N_spam/N)\n",
    "    log_p_legit = np.log(1-(N_spam/N))\n",
    "    log_pspam_x = log_p_spam+log_px_spam\n",
    "    log_plegit_x = log_p_legit+log_px_legit\n",
    "    if(log_pspam_x>log_plegit_x):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def predit(test_mails, test_labels, features, feature_matrix, N, spam_train_mails):\n",
    "    predicted = []\n",
    "    processed_test = preprocessing(test_mails)\n",
    "    for mail in tqdm(processed_test):\n",
    "        predicted.append(BernoulliNBclassifier(mail.split(' '), feature_matrix, features, N, spam_train_mails))\n",
    "        \n",
    "    return predicted\n",
    "\n",
    "predicted_labels = predit(test_emails, test_labels, extracted_features, feature_matrix, len(train_labels), sum(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e07a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, predicted_labels))\n",
    "\n",
    "print(confusion_matrix(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd64de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train, train_labels)\n",
    "test_email_count = vectorizer.transform(preprocessing(test_emails))\n",
    "test_pred = model.predict(test_email_count)\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10382653",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes with Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbcebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = preprocessing(train_emails)\n",
    "processed_test = preprocessing(test_emails)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vec = vectorizer.fit_transform(processed_train)\n",
    "vocab = vectorizer.vocabulary_\n",
    "vocab = dict((v,k) for k,v in vocab.items())\n",
    "X_train = vec.toarray()\n",
    "\n",
    "TF_matrix = get_feature_matrix(processed_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c005c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultinomialNBclassifierBF(X, feature_matrix, features, N, N_spam):\n",
    "    log_px_spam = 0\n",
    "    log_px_legit = 0\n",
    "    M = np.shape(feature_matrix)[1]\n",
    "    [den1, den2] = np.sum(feature_matrix,axis=1)\n",
    "    for i in features.keys():\n",
    "        #print(feature_matrix[0][i]+1)\n",
    "        p_is = (feature_matrix[0][i]+1)/(den1+M)\n",
    "        p_il = (feature_matrix[1][i]+1)/(den2+M)\n",
    "        if features[i] in X:\n",
    "            log_px_spam = log_px_spam + np.log(p_is)\n",
    "            log_px_legit = log_px_legit + np.log(p_il)\n",
    "\n",
    "    log_p_spam = np.log(N_spam/N)\n",
    "    log_p_legit = np.log(1-(N_spam/N))\n",
    "    log_pspam_x = log_p_spam+log_px_spam\n",
    "    log_plegit_x = log_p_legit+log_px_legit\n",
    "    if(log_pspam_x>log_plegit_x):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def predit(test_mails, test_labels, features, feature_matrix, N, spam_train_mails):\n",
    "    predicted = []\n",
    "    processed_test = preprocessing(test_mails)\n",
    "    for mail in tqdm(processed_test):\n",
    "        predicted.append(MultinomialNBclassifierBF(mail.split(' '), feature_matrix, features, N, spam_train_mails))\n",
    "        \n",
    "    return predicted\n",
    "\n",
    "predicted_labels = predit(test_emails, test_labels, extracted_features, TF_matrix, len(train_labels), sum(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c07b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, predicted_labels))\n",
    "\n",
    "print(confusion_matrix(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7da740",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultinomialclassifierTF(X, feature_matrix, features, N, N_spam):\n",
    "    log_px_spam = 0\n",
    "    log_px_legit = 0\n",
    "    M = np.shape(feature_matrix)[1]\n",
    "    [den1, den2] = np.sum(feature_matrix,axis=1)\n",
    "    for i in features.keys():\n",
    "        #print(feature_matrix[0][i]+1)\n",
    "        p_is = (feature_matrix[0][i]+1)/(den1+M)\n",
    "        p_il = (feature_matrix[1][i]+1)/(den2+M)\n",
    "        if features[i] in X:\n",
    "            x_i = X.count(features[i])\n",
    "            log_px_spam = log_px_spam + x_i*np.log(p_is)\n",
    "            log_px_legit = log_px_legit + x_i*np.log(p_il)\n",
    "\n",
    "    log_p_spam = np.log(N_spam/N)\n",
    "    log_p_legit = np.log(1-(N_spam/N))\n",
    "    log_pspam_x = log_p_spam+log_px_spam\n",
    "    log_plegit_x = log_p_legit+log_px_legit\n",
    "    if(log_pspam_x>log_plegit_x):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def predit(test_mails, test_labels, features, feature_matrix, N, spam_train_mails):\n",
    "    predicted = []\n",
    "    processed_test = preprocessing(test_mails)\n",
    "    for mail in tqdm(processed_test):\n",
    "        predicted.append(MultinomialclassifierTF(mail.split(' '), feature_matrix, features, N, spam_train_mails))\n",
    "        \n",
    "    return predicted\n",
    "\n",
    "predicted_labels = predit(test_emails, test_labels, extracted_features, TF_matrix, len(train_labels), sum(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, predicted_labels))\n",
    "\n",
    "print(confusion_matrix(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f0b8fa",
   "metadata": {},
   "source": [
    "## SVM Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "099a30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfvectorizer = CountVectorizer()\n",
    "vec = tfidfvectorizer.fit_transform(processed_train)\n",
    "vocab = vectorizer.vocabulary_\n",
    "vocab = dict((v,k) for k,v in vocab.items())\n",
    "X_train = vec.toarray()\n",
    "\n",
    "def get_Xfeatures(X_, extracted_features):\n",
    "    X = []\n",
    "    for i in range(len(X_)):\n",
    "        X.append([X_[i][k] for k in extracted_features.keys()])\n",
    "    X = np.array(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "X = get_Xfeatures(X_train, extracted_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3338a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_Xfeatures(tfidfvectorizer.transform(processed_test).toarray(), extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b448b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_soft_margin:\n",
    "\n",
    "    def __init__(self, alpha = 0.1, lambda_ = 0.1, n_iterations = 1000):\n",
    "        self.alpha = alpha # learning rate\n",
    "        self.lambda_ = lambda_ # tradeoff\n",
    "        self.n_iterations = n_iterations # number of iterations\n",
    "        self.w = None # weights or slopes\n",
    "        self.b = None # intercept\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        n_samples, n_features = X.shape        \n",
    "        self.w = np.zeros(n_features) # initalizing with 0\n",
    "        self.b = 0 # initializewith 0\n",
    "        \n",
    "        for iteration in range(self.n_iterations):\n",
    "            for i, Xi in enumerate(X):\n",
    "                # yixiw-b≥1\n",
    "                if y[i] * (np.dot(Xi, self.w) - self.b) >= 1 : \n",
    "                    self.w -= self.alpha * (2 * self.lambda_ * self.w) # w = w + α* (2λw - yixi)\n",
    "                else:\n",
    "                    self.w -= self.alpha * (2 * self.lambda_ * self.w - np.dot(Xi, y[i])) # w = w + α* (2λw - yixi)\n",
    "                    self.b -= self.alpha * y[i] # b = b - α* (yi)\n",
    "        return self.w, self.b\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.dot(X, self.w) - self.b \n",
    "        result = [1 if val > 0 else -1 for val in pred] # returning in the form of -1 and 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVM_soft_margin()\n",
    "clf.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e47779",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(X)\n",
    "\n",
    "print(np.unique(predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1db97795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_Dual:\n",
    "\n",
    "    def __init__(self, kernel='poly', degree=2, sigma=0.01, epoches=1000, learning_rate= 0.01):\n",
    "        self.alpha = None\n",
    "        self.b = 0\n",
    "        self.degree = degree\n",
    "        self.c = 1\n",
    "        self.C = 1\n",
    "        self.sigma = sigma\n",
    "        self.epoches = epoches\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        if kernel == 'poly':\n",
    "            self.kernel = self.polynomial_kernal # for polynomial kernal\n",
    "        elif kernel == 'rbf':\n",
    "            self.kernel =  self.gaussian_kernal # for guassian\n",
    "\n",
    "    def polynomial_kernal(self,X,Z):\n",
    "        return (self.c + X.dot(Z.T))**self.degree #(c + X.y)^degree\n",
    "        \n",
    "    def gaussian_kernal(self, X,Z):\n",
    "        return np.exp(-(1 / self.sigma ** 2) * np.linalg.norm(X[:, np.newaxis] - Z[np.newaxis, :], axis=2) ** 2) #e ^-(1/ σ2) ||X-y|| ^2\n",
    "    \n",
    "    def train(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.alpha = np.random.random(X.shape[0])\n",
    "        self.b = 0\n",
    "        self.ones = np.ones(X.shape[0]) \n",
    "\n",
    "        y_mul_kernal = np.outer(y, y) * self.kernel(X, X) # yi yj K(xi, xj)\n",
    "\n",
    "        for i in range(self.epoches):\n",
    "            gradient = self.ones - y_mul_kernal.dot(self.alpha) # 1 – yk ∑ αj yj K(xj, xk)\n",
    "\n",
    "            self.alpha += self.learning_rate * gradient # α = α + η*(1 – yk ∑ αj yj K(xj, xk)) to maximize\n",
    "            self.alpha[self.alpha > self.C] = self.C # 0<α<C\n",
    "            self.alpha[self.alpha < 0] = 0 # 0<α<C\n",
    "\n",
    "            loss = np.sum(self.alpha) - 0.5 * np.sum(np.outer(self.alpha, self.alpha) * y_mul_kernal) # ∑αi – (1/2) ∑i ∑j αi αj yi yj K(xi, xj)\n",
    "            \n",
    "        alpha_index = np.where((self.alpha) > 0 & (self.alpha < self.C))[0]\n",
    "        \n",
    "        # for intercept b, we will only consider α which are 0<α<C \n",
    "        b_list = []        \n",
    "        for index in alpha_index:\n",
    "            b_list.append(y[index] - (self.alpha * y).dot(self.kernel(X, X[index])))\n",
    "\n",
    "        self.b = np.mean(b_list) # avgC≤αi≤0{ yi – ∑αjyj K(xj, xi) }\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.mean(y == y_hat)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return (self.alpha * self.y).dot(self.kernel(self.X, X)) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61f2fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVM_Dual()\n",
    "clf.train(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db902c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18c0c9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       242\n",
      "           1       1.00      0.22      0.37        49\n",
      "\n",
      "    accuracy                           0.87       291\n",
      "   macro avg       0.93      0.61      0.65       291\n",
      "weighted avg       0.89      0.87      0.83       291\n",
      "\n",
      "[[242   0]\n",
      " [ 38  11]]\n"
     ]
    }
   ],
   "source": [
    "predicted = np.where(predicted_labels == -1, 0, 1)\n",
    "print(classification_report(test_labels, predicted))\n",
    "print(confusion_matrix(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154a3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
