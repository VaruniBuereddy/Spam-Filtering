{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b31b42c",
   "metadata": {},
   "source": [
    "# EL-GY-9133 Machine Learning for Cyber-Security\n",
    "\n",
    "## Lab 2: E-mail Spam Filtering\n",
    "\n",
    "#### Name: Varuni Buereddy\n",
    "#### Net-ID: vb2386\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1a625",
   "metadata": {},
   "source": [
    "### Overview\n",
    "In this lab, We will design an e-mail spam filter using a Naïve Bayes and SVM based classification on the ling-spam dataset. We will explore the impact of feature selection and compare the performance of different variants of an NB classifier and also implement SVM based classifier. \n",
    "\n",
    "### Dataset\n",
    "The ling-spam corpus contains e-mails from the Linguist mailing list categorized as either legitimate or spam emails. The corpus is divided into four sub-folders that contain the same emails that are pre-processed with/without lemmatization and with/without stop-word removal. The e-mails in each sub-folder partitioned into 10 \"folds.\"\n",
    "In this lab, we will use the first 9 folds from the ling-spam corpus as training data, and the 10th fold as test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1486d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157dbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = './lingspam_public/lemm_stop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cf68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfolder = os.listdir(path_to_dataset)\n",
    "trainfolder.remove('part10')\n",
    "testfolder = 'part10'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462cad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading from folder\n",
    "def load_from_folder(folder, email_texts, labels):\n",
    "    folder = os.path.join(path_to_dataset,folder)\n",
    "    files = [os.path.join(folder,f) for f in os.listdir(folder)]\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            for i,line in enumerate(f):\n",
    "                if(i==2): \n",
    "                    email_texts.append(line)\n",
    "        if(file.startswith(folder+'/spmsg')):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0337e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************Training dataset:**************\n",
      "Number of Spam Emails: 432\n",
      "Number of Legit Emails: 2170\n",
      "************Test dataset:**************\n",
      "Number of Spam Emails: 49\n",
      "Number of Legit Emails: 242\n"
     ]
    }
   ],
   "source": [
    "train_emails = []\n",
    "train_labels = []\n",
    "test_emails = []\n",
    "test_labels = []\n",
    "\n",
    "for folder in trainfolder:\n",
    "    load_from_folder(folder, train_emails, train_labels)\n",
    "    \n",
    "load_from_folder(testfolder, test_emails, test_labels)\n",
    "\n",
    "N_spam = sum(train_labels)\n",
    "N_spam_test = sum(test_labels)\n",
    "print(\"************Training dataset:**************\")\n",
    "print(f\"Number of Spam Emails: {N_spam}\")\n",
    "print(f\"Number of Legit Emails: {len(train_labels)-N_spam}\")\n",
    "\n",
    "print(\"************Test dataset:**************\")\n",
    "print(f\"Number of Spam Emails: {sum(test_labels)}\")\n",
    "print(f\"Number of Legit Emails: {len(test_labels)-N_spam_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88153667",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEmCAYAAAB8oNeFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuQ0lEQVR4nO3de1wU9d4H8M8udwQWEdxdEsEO3lA0w0topQUJXtCMTIsn8ZI+mkTKKc28YVSWJSimeSoVPGJejsJjmpwQ74o3HslUpCIMfVxQREAkue08f/hijis4sriwC3zevebVzsxvZr6zL3c/zGXnJxMEQQAREdFDyI1dABERmTYGBRERSWJQEBGRJAYFERFJYlAQEZEkBgUREUliUBARkSQGBRERSTI3dgHNgVarxbVr12Bvbw+ZTGbscoiIHpsgCLh9+zZcXV0hl0sfMzAo6uHatWtwc3MzdhlERAZ35coVdOjQQbINg6Ie7O3tAdx7Qx0cHIxcDRHR4yspKYGbm5v4/SaFQVEPNaebHBwcGBRE1KLU53Q6L2YTEZEkBgUREUliUBARkSReoyAio6qurkZlZaWxy2iRLCwsYGZm9tjrYVAQkdGUlpbi6tWrYP9pjUMmk6FDhw6ws7N7rPUwKIjIKKqrq3H16lXY2trCxcWFP2Y1MEEQcOPGDVy9ehWdO3d+rCMLBgURGUVlZSUEQYCLiwtsbGyMXU6L5OLigsuXL6OyspJBQdKKi4tRVlZm1BpsbW2hUCiMWgOZJh5JNB5DvbcMihauuLgYsV/FQlulNWodcnM5wsPCGRZEzRCDooUrKyuDtkqLHdiBAhQYpQZnOCO4KhhlZWUMCqJmiEHRShSgABpojF0G0SM19alSnhZ9NAYFEZmM4uJirI6NRaW26U6VWsjlmBmu32nRGzduYNGiRdizZw/y8/PRtm1b9O7dG4sWLcKgQYMasVrjYFAQkckoKytDpVaLMTt2wKWg8U+V3nB2RmKw/qdFg4ODUVFRgfj4eDz55JPIz89Hamoqbt682YjVGg+DgohMjktBAdQa0zxVWlRUhCNHjuDgwYMYPHgwAMDd3R39+/cX28hkMqxZswa7du3CwYMHoVarsWzZMrz66qtim7lz5yIxMRFXr16FSqVCSEgIFi1aBAsLCwBAZGQkkpKSEB4ejsjISBQWFmLChAlYtWoVli9fjujoaGi1Wrz77ruYP39+o+4zn/VERKQHOzs72NnZISkpCeXl5Q9tt3DhQgQHB+Pnn39GSEgIxo8fj8zMTHG+vb094uLicPHiRaxcuRLffvstYmJidNaRnZ2NvXv3Ijk5Gd9//z3WrVuHESNG4OrVqzh06BA+//xzLFiwACdPnmy0/QUYFEREejE3N0dcXBzi4+Ph6OiIQYMG4cMPP8S5c+d02o0dOxZvvfUWunTpgqioKPTt2xerVq0S5y9YsAADBw6Eh4cHgoKC8N5772Hbtm0669BqtVi/fj28vLwQFBSEF154AVlZWVixYgW6du2KSZMmoWvXrjhw4ECj7jODgohIT8HBwbh27Rp27dqFwMBAHDx4EE8//TTi4uLENr6+vjrL+Pr66hxRbN26FYMGDYJKpYKdnR0WLFiA3NxcnWU8PDx0eqBTKpXw8vLS6eNaqVTi+vXrBt5DXQwKIqIGsLa2xksvvYSFCxfi+PHjmDhxIhYvXlyvZdPS0hASEoLhw4dj9+7dOHv2LObPn4+KigqddjXXK2rIZLI6p2kb+S4xBgURkQF4eXnhzp074viJEyd05p84cQLdu3cHABw/fhzu7u6YP38++vbti86dO+PPP/9s0nr1wbueiMjk3HB2Ntnt3Lx5E2PHjsXkyZPRq1cv2Nvb48yZM1i2bBlGjx4tttu+fTv69u2LZ599FgkJCTh16hTWrVsHAOjcuTNyc3OxZcsW9OvXD3v27EFiYqLB9svQGBREZDJsbW1hIZcjMTi4ybZpIZfD1ta23u3t7OwwYMAAxMTEIDs7G5WVlXBzc8PUqVPx4Ycfiu2WLFmCLVu24O2334Zarcb3338PLy8vAMCoUaMwe/ZshIWFoby8HCNGjMDChQsRGRlp6N0zCJlgxB5Dli5dip07d+LSpUuwsbHBwIED8fnnn6Nr165im7t37+Lvf/87tmzZgvLycgQEBGDNmjVQKpVim9zcXMyYMQMHDhyAnZ0dQkNDsXTpUpib/ycHDx48iIiICFy4cAFubm5YsGABJk6cWK86S0pKoFAoUFxcDAcHB4Ptf1PQaDT45ptv8A/8w2iP8FBDjf/Gf2PatGlQq9VGqYFMz927d5GTk4NOnTrB2tpanN4SHuEhk8mQmJiIl19+2aDr1dfD3mNAv+81ox5RHDp0CDNnzkS/fv1QVVWFDz/8EEOHDsXFixfRpk0bAMDs2bOxZ88ebN++HQqFAmFhYXjllVdw7NgxAPc6PxkxYgRUKhWOHz8OjUaDCRMmwMLCAp9++ikAICcnByNGjMD06dORkJCA1NRUvPXWW1Cr1QgICDDa/hNRbQqFgs9eMjFGDYrk5GSd8bi4OLRv3x7p6el4/vnnUVxcjHXr1mHz5s148cUXAQAbNmxA9+7dceLECTzzzDP46aefcPHiRezbtw9KpRJPPfUUoqKiMHfuXERGRsLS0hJr165Fp06dsHz5cgBA9+7dcfToUcTExDAoiIgewaTueiouLgYAODk5AQDS09NRWVkJf39/sU23bt3QsWNHpKWlAbh3m5m3t7fOqaiAgACUlJTgwoULYpv711HTpmYdDyovL0dJSYnOQERUX4IgGP20kyGZTFBotVrMmjULgwYNQs+ePQEAeXl5sLS0hKOjo05bpVKJvLw8sc39IVEzv2aeVJuSkhL89ddftWpZunSpePirUCjg5uZmkH0kImqOTCYoZs6cifPnz2PLli3GLgXz5s1DcXGxOFy5csXYJRERGY1J3B4bFhaG3bt34/Dhw+jQoYM4XaVSoaKiAkVFRTpHFfn5+VCpVGKbU6dO6awvPz9fnFfz/5pp97dxcHCos1N3KysrWFlZGWTfiIiaO6MeUQiCgLCwMCQmJmL//v3o1KmTznwfHx9YWFggNTVVnJaVlYXc3FzxOSq+vr745ZdfdJ51kpKSAgcHB/GeZV9fX5111LR58FksRERUm1GPKGbOnInNmzfjf/7nf2Bvby9eU1AoFLCxsYFCocCUKVMQEREBJycnODg44J133oGvry+eeeYZAMDQoUPh5eWFN998E8uWLUNeXh4WLFiAmTNnikcF06dPx1dffYU5c+Zg8uTJ2L9/P7Zt24Y9e/YYbd+JiJoLowbF119/DQAYMmSIzvQNGzaIP4aLiYmBXC5HcHCwzg/uapiZmWH37t2YMWMGfH190aZNG4SGhuKjjz4S23Tq1Al79uzB7NmzsXLlSnTo0AHfffcdb40lMkEt4Qd3j8vDwwOzZs3CrFmzjF0KACMHRX1+FG5tbY3Vq1dj9erVD23j7u6OH3/8UXI9Q4YMwdmzZ/WukYiaTnFxMWK/ioW2qun6zJabyxEepl+f2RMnTkRRURGSkpIapabTp0+LPzoGjP9Lb5O4mE1EBNzrM1tbpcUO7EABGr/PbGc4I7hK/z6zG5uLi4uxS9BhMrfHEhHVKEABNE3wX2OE0fnz5zFs2DDY2dlBqVTizTffREHBf7Zz+/ZthISEoE2bNlCr1YiJicGQIUN0TjN5eHhgxYoV4msAGDNmDGQymTjelBgUREQGUlRUhBdffBF9+vTBmTNnkJycjPz8fLz22mtim4iICBw7dgy7du1CSkoKjhw5gv/93/996DpPnz4N4N61W41GI443JZ56IiIykK+++gp9+vQRH0gKAOvXr4ebmxt+/fVXqNVqxMfHY/PmzfDz8wNwLwBcXV0fus6a01COjo7ib8OaGoOCiMhAfv75Z7G7gwdlZ2fjr7/+QmVlJfr37y9OVygUOl0rmCIGBRGRgZSWliIoKAiff/55rXlqtRq///67Eap6fAwKIiIDefrpp7Fjxw54eHjodJxW48knn4SFhQVOnz6Njh07Arh3S/Cvv/6K559//qHrtbCwQHV1daPV/Si8mE1E1ADFxcXIyMjQGaZNm4bCwkK8/vrrOH36NLKzs/Hvf/8bkyZNQnV1Nezt7REaGor3338fBw4cwIULFzBlyhTI5XLIZLKHbsvDwwOpqanIy8vDrVu3mnAv7+ERBRGZHGc4m/x2Dh48iD59+uhMmzJlCo4dO4a5c+di6NChKC8vh7u7OwIDAyGX3/u7PDo6GtOnT8fIkSPh4OCAOXPm4MqVK7W6Kr3f8uXLERERgW+//RZPPPEELl++3OC6G4JBQUQmw9bWFnJzOYKrgptsm3JzOWxtbfVaJi4uDnFxcQ+dv3PnzofOs7e3R0JCgjh+584dLFmyBNOmTROnPRgEQUFBCAoK0qtGQ2JQEJHJUCgUCA8Lb9HPejp79iwuXbqE/v37o7i4WHwu3ejRo5usBn0xKIjIpNT0LNmSffnll8jKyoKlpSV8fHxw5MgRODs3zem2hmBQEBE1oT59+iA9Pd3YZeiFdz0REZEkBgUREUliUBCRUdWnXxpqGEO9twwKIjIKMzMzAEBFRYWRK2m5at7bmve6oXgxm4iMwtzcHLa2trhx4wYsLCzEH6SRYWi1Wty4cQO2trZ1Pk5EHwwKIjIKmUwGtVqNnJwc/Pnnn8Yup0WSy+Xo2LGj5ONB6oNBQURGY2lpic6dO/P0UyOxtLQ0yJEag4KIjEoul0s+54iMjycFiYhIEoOCiIgkMSiIiEgSg4KIiCQxKIiISBKDgoiIJDEoiIhIEoOCiIgkMSiIiEgSg4KIiCQxKIiISBKDgoiIJDEoiIhIEoOCiIgkMSiIiEgSg4KIiCQxKIiISNJjB0V1dTUyMjJw69YtQ9RDREQmRu+gmDVrFtatWwfgXkgMHjwYTz/9NNzc3HDw4EG91nX48GEEBQXB1dUVMpkMSUlJOvMnTpwImUymMwQGBuq0KSwsREhICBwcHODo6IgpU6agtLRUp825c+fw3HPPwdraGm5ubli2bJm+u01E1GrpHRT/+te/0Lt3bwDADz/8gJycHFy6dAmzZ8/G/Pnz9VrXnTt30Lt3b6xevfqhbQIDA6HRaMTh+++/15kfEhKCCxcuICUlBbt378bhw4cxbdo0cX5JSQmGDh0Kd3d3pKen44svvkBkZCS++eYbvWolImqtzPVdoKCgACqVCgDw448/YuzYsejSpQsmT56MlStX6rWuYcOGYdiwYZJtrKysxO09KDMzE8nJyTh9+jT69u0LAFi1ahWGDx+OL7/8Eq6urkhISEBFRQXWr18PS0tL9OjRAxkZGYiOjtYJFCIiqpveRxRKpRIXL15EdXU1kpOT8dJLLwEAysrKYGZmZvACDx48iPbt26Nr166YMWMGbt68Kc5LS0uDo6OjGBIA4O/vD7lcjpMnT4ptnn/+eVhaWoptAgICkJWVxesqRET1oPcRxaRJk/Daa69BrVZDJpPB398fAHDy5El069bNoMUFBgbilVdeQadOnZCdnY0PP/wQw4YNQ1paGszMzJCXl4f27dvrLGNubg4nJyfk5eUBAPLy8tCpUyedNkqlUpzXtm3bWtstLy9HeXm5OF5SUmLQ/SIiak70DorIyEj07NkTV65cwdixY2FlZQUAMDMzwwcffGDQ4saPHy++9vb2Rq9evfC3v/0NBw8ehJ+fn0G3db+lS5diyZIljbZ+IqLmRO+gAIBXX3211rTQ0NDHLuZRnnzySTg7O+P333+Hn58fVCoVrl+/rtOmqqoKhYWF4nUNlUqF/Px8nTY14w+79jFv3jxERESI4yUlJXBzczPkrhARNRv1CorY2Nh6rzA8PLzBxTzK1atXcfPmTajVagCAr68vioqKkJ6eDh8fHwDA/v37odVqMWDAALHN/PnzUVlZCQsLCwBASkoKunbtWudpJ+DeBfSaIyUiotauXkERExNTr5XJZDK9gqK0tBS///67OJ6Tk4OMjAw4OTnByckJS5YsQXBwMFQqFbKzszFnzhx4enoiICAAANC9e3cEBgZi6tSpWLt2LSorKxEWFobx48fD1dUVAPDGG29gyZIlmDJlCubOnYvz589j5cqV9d4nIqLWrl5BkZOT0ygbP3PmDF544QVxvOZ0T2hoKL7++mucO3cO8fHxKCoqgqurK4YOHYqoqCidv/YTEhIQFhYGPz8/yOVyBAcH6xwBKRQK/PTTT5g5cyZ8fHzg7OyMRYsW8dZYIqJ6atA1CkMZMmQIBEF46Px///vfj1yHk5MTNm/eLNmmV69eOHLkiN71ERFRPYMiIiICUVFRaNOmjc5F3rpER0cbpDAiIjIN9QqKs2fPorKyUnz9MDKZzDBVERGRyahXUBw4cKDO10RE1PKxPwoiIpLUoIvZZ86cwbZt25Cbm4uKigqdeTt37jRIYUREZBr0PqLYsmULBg4ciMzMTCQmJqKyshIXLlzA/v37oVAoGqNGIiIyIr2D4tNPP0VMTAx++OEHWFpaYuXKlbh06RJee+01dOzYsTFqJCIiI9I7KLKzszFixAgAgKWlJe7cuQOZTIbZs2ezMyAiohZI76Bo27Ytbt++DQB44okncP78eQBAUVERysrKDFsdEREZnd4Xs59//nmkpKTA29sbY8eOxbvvvov9+/cjJSWlUR/9TURExqF3UHz11Ve4e/cuAGD+/PmwsLDA8ePHERwcjAULFhi8QCIiMi69g8LJyUl8LZfLDd5ZERERmZYGPxTw+vXruH79OrRarc70Xr16PXZRRERkOvQOivT0dISGhiIzM7PWk19lMhmqq6sNVhwRERmf3kExefJkdOnSBevWrYNSqeSDAImIWji9g+KPP/7Ajh074Onp2Rj1EBGRidH7dxR+fn74+eefG6MWIiIyQXofUXz33XcIDQ3F+fPn0bNnT1hYWOjMHzVqlMGKIyIi49M7KNLS0nDs2DHs3bu31jxezCYiann0PvX0zjvv4L/+67+g0Wig1Wp1BoYEEVHLo3dQ3Lx5E7Nnz4ZSqWyMeoiIyMToHRSvvPIKu0MlImpF9L5G0aVLF8ybNw9Hjx6Ft7d3rYvZ4eHhBiuOiIiMr0F3PdnZ2eHQoUM4dOiQzjyZTMagICJqYfQOipycnMaog4iITJTe1yiIiKh1qXdQeHl5obCwUBx/++23UVBQII5fv34dtra2hq2OiIiMrt5BcenSJVRVVYnjmzZtQklJiTguCILYoREREbUcDT719OAjxgHwSbJERC0Qr1EQEZGkegeFTCardcTAIwgiopav3rfHCoIAPz8/mJvfW+Svv/5CUFAQLC0tAUDn+gUREbUc9Q6KxYsX64yPHj26Vpvg4ODHr4iIiExKg4OCiIhaB17MJiIiSQwKIiKSxKAgIiJJDAoiIpJUr6BwcnISn+s0efJk3L59u1GLIiIi01GvoKioqBCf6xQfH89nOhERtSL1CgpfX1+8/PLLmDRpEgRBQHh4OCZPnlznoI/Dhw8jKCgIrq6ukMlkSEpK0pkvCAIWLVoEtVoNGxsb+Pv747ffftNpU1hYiJCQEDg4OMDR0RFTpkxBaWmpTptz587hueeeg7W1Ndzc3LBs2TK96iQias3qFRSbNm3C8OHDUVpaCplMhuLiYty6davOQR937txB7969sXr16jrnL1u2DLGxsVi7di1OnjyJNm3aICAgQOeIJiQkBBcuXEBKSgp2796Nw4cPY9q0aeL8kpISDB06FO7u7khPT8cXX3yByMhIfPPNN3rVSkTUWtXrB3dKpRKfffYZAKBTp0745z//iXbt2j32xocNG4Zhw4bVOU8QBKxYsQILFiwQfwW+ceNGKJVKJCUlYfz48cjMzERycjJOnz6Nvn37AgBWrVqF4cOH48svv4SrqysSEhJQUVGB9evXw9LSEj169EBGRgaio6N1AoWIiOqm911POTk5BgmJ+mwnLy8P/v7+4jSFQoEBAwYgLS0NAJCWlgZHR0cxJADA398fcrkcJ0+eFNs8//zz4jOpACAgIABZWVkPPQIqLy9HSUmJzkBE1Fo16PbYQ4cOISgoCJ6envD09MSoUaNw5MgRgxaWl5cH4N7RzP2USqU4Ly8vD+3bt9eZb25uDicnJ502da3j/m08aOnSpVAoFOLg5ub2+DtERNRM6R0UmzZtgr+/P2xtbREeHo7w8HDY2NjAz88Pmzdvbowam9y8efNQXFwsDleuXDF2SURERlPvhwLW+OSTT7Bs2TLMnj1bnBYeHo7o6GhERUXhjTfeMEhhKpUKAJCfnw+1Wi1Oz8/Px1NPPSW2uX79us5yVVVVKCwsFJdXqVTIz8/XaVMzXtPmQVZWVrCysjLIfhARNXd6H1H88ccfCAoKqjV91KhRyMnJMUhRwL2L5iqVCqmpqeK0kpISnDx5Er6+vgDu3bZbVFSE9PR0sc3+/fuh1WoxYMAAsc3hw4dRWVkptklJSUHXrl3Rtm1bg9VLRNRS6R0Ubm5uOl/eNfbt26f3ufzS0lJkZGQgIyMDwL0L2BkZGcjNzYVMJsOsWbPw8ccfY9euXfjll18wYcIEuLq64uWXXwYAdO/eHYGBgZg6dSpOnTqFY8eOISwsDOPHj4erqysA4I033oClpSWmTJmCCxcuYOvWrVi5ciUiIiL03XUiolZJ71NPf//73xEeHo6MjAwMHDgQAHDs2DHExcVh5cqVeq3rzJkzeOGFF8Txmi/v0NBQxMXFYc6cObhz5w6mTZuGoqIiPPvss0hOToa1tbW4TEJCAsLCwuDn5we5XI7g4GDExsaK8xUKBX766SfMnDkTPj4+cHZ2xqJFi3hrLBFRPckEQRD0XSgxMRHLly9HZmYmgHt/2b///vt19nrXEpSUlEChUKC4uBgODg7GLkcvGo0G33zzDf6Bf0ADjVFqUEON/8Z/Y9q0aTrXm4jIePT5XtP7iAIAxowZgzFjxjSoOCIial74mHEiIpLEoCAiIkkMCiIiksSgICIiSY8VFIIgoAE3TRERUTPSoKDYuHEjvL29YWNjAxsbG/Tq1Qv//Oc/DV0bERGZAL1vj42OjsbChQsRFhaGQYMGAQCOHj2K6dOno6CgQOcZUERE1PzpHRSrVq3C119/jQkTJojTRo0ahR49eiAyMpJBQUTUwuh96kmj0YiP7rjfwIEDodEY55e/RETUePQOCk9PT2zbtq3W9K1bt6Jz584GKYqIiEyH3qeelixZgnHjxuHw4cPiNYpjx44hNTW1zgAhIqLmTe8jiuDgYJw8eRLOzs5ISkpCUlISnJ2dcerUKT7/iYioBWrQQwF9fHywadMmQ9dCREQmiL/MJiIiSfU+opDL5ZDJZJJtZDIZqqqqHrsoIiIyHfUOisTExIfOS0tLQ2xsLLRarUGKIiIi01HvoKir97qsrCx88MEH+OGHHxASEoKPPvrIoMUREZHxNegaxbVr1zB16lR4e3ujqqoKGRkZiI+Ph7u7u6HrIyIiI9MrKIqLizF37lx4enriwoULSE1NxQ8//ICePXs2Vn1ERGRk9T71tGzZMnz++edQqVT4/vvv6zwVRURELU+9g+KDDz6AjY0NPD09ER8fj/j4+Drb7dy502DFERGR8dU7KCZMmPDI22OJiKjlqXdQxMXFNWIZRERkqvjLbCIiksSgICIiSQwKIiKSxKAgIiJJDAoiIpLEoCAiIkkMCiIiksSgICIiSQwKIiKSxKAgIiJJDAoiIpLEoCAiIkkMCiIiksSgICIiSQwKIiKSxKAgIiJJJh0UkZGRkMlkOkO3bt3E+Xfv3sXMmTPRrl072NnZITg4GPn5+TrryM3NxYgRI2Bra4v27dvj/fffR1VVVVPvChFRs1XvHu6MpUePHti3b584bm7+n5Jnz56NPXv2YPv27VAoFAgLC8Mrr7yCY8eOAQCqq6sxYsQIqFQqHD9+HBqNBhMmTICFhQU+/fTTJt8XIqLmyOSDwtzcHCqVqtb04uJirFu3Dps3b8aLL74IANiwYQO6d++OEydO4JlnnsFPP/2EixcvYt++fVAqlXjqqacQFRWFuXPnIjIyEpaWlk29O0REzY5Jn3oCgN9++w2urq548sknERISgtzcXABAeno6Kisr4e/vL7bt1q0bOnbsiLS0NABAWloavL29oVQqxTYBAQEoKSnBhQsXHrrN8vJylJSU6AxERK2VSQfFgAEDEBcXh+TkZHz99dfIycnBc889h9u3byMvLw+WlpZwdHTUWUapVCIvLw8AkJeXpxMSNfNr5j3M0qVLoVAoxMHNzc2wO0ZE1IyY9KmnYcOGia979eqFAQMGwN3dHdu2bYONjU2jbXfevHmIiIgQx0tKShgWRNRqmfQRxYMcHR3RpUsX/P7771CpVKioqEBRUZFOm/z8fPGahkqlqnUXVM14Xdc9alhZWcHBwUFnICJqrZpVUJSWliI7OxtqtRo+Pj6wsLBAamqqOD8rKwu5ubnw9fUFAPj6+uKXX37B9evXxTYpKSlwcHCAl5dXk9dPRNQcmfSpp/feew9BQUFwd3fHtWvXsHjxYpiZmeH111+HQqHAlClTEBERAScnJzg4OOCdd96Br68vnnnmGQDA0KFD4eXlhTfffBPLli1DXl4eFixYgJkzZ8LKysrIe0dE1DyYdFBcvXoVr7/+Om7evAkXFxc8++yzOHHiBFxcXAAAMTExkMvlCA4ORnl5OQICArBmzRpxeTMzM+zevRszZsyAr68v2rRpg9DQUHz00UfG2iUiombHpINiy5YtkvOtra2xevVqrF69+qFt3N3d8eOPPxq6tHorLi5GWVmZ0bZfUFBgtG0TUctg0kHR3BUXF2N1bCwqtVpjl0JE1GAMikZUVlaGSq0WY3bsgIuR/rL/zdMTB/z8jLJtImoZGBRNwKWgAGqNxijbLnB2Nsp2iajlaFa3xxIRUdNjUBARkSQGBRERSWJQEBGRJAYFERFJYlAQEZEkBgUREUliUBARkSQGBRERSWJQEBGRJAYFERFJYlAQEZEkBgUREUliUBARkSQGBRERSWJ/FEREj8nYXR7b2tpCoVA02voZFEREj6G4uBixX8VCW2W8Lo/l5nKEh4U3WlgwKIiIHkNZWRm0VVrswA4UoOm7PHaGM4KrglFWVsagICIyZQUogAbG6fK4sfFiNhERSWJQEBGRJAYFERFJYlAQEZEkBgUREUliUBARkSQGBRERSWJQEBGRJAYFERFJYlAQEZEkBgUREUliUBARkSQGBRERSWJQEBGRJAYFERFJYlAQEZEkdlxERM2asfurLiho+l7tmhqDgoiareLiYqyOjUWl1nj9VbcGrSooVq9ejS+++AJ5eXno3bs3Vq1ahf79+xu7LCJqoLKyMlRqtRizYwdcjPSX/W+enjjg52eUbTeVVhMUW7duRUREBNauXYsBAwZgxYoVCAgIQFZWFtq3b2/s8ojoMbgUFECtMU5/1QXOzkbZblNqNRezo6OjMXXqVEyaNAleXl5Yu3YtbG1tsX79emOXRkRk0lrFEUVFRQXS09Mxb948cZpcLoe/vz/S0tJqtS8vL0d5ebk4XlxcDAAoKSnRa7u3b9/G3bt3kdO2LW4b6RzqVTs73L17F23RFloYp4a2aIu7uIvbt2+jTZs2RqmBWiZ+xhr++ar5PhME4dGNhVbg//7v/wQAwvHjx3Wmv//++0L//v1rtV+8eLEAgAMHDhxa/HDlypVHfoe2iiMKfc2bNw8RERHiuFarRWFhIdq1aweZTGbEyppeSUkJ3NzccOXKFTg4OBi7HKIWx1ifMUEQcPv2bbi6uj6ybasICmdnZ5iZmSE/P19nen5+PlQqVa32VlZWsLKy0pnm6OjYmCWaPAcHBwYFUSMyxmdMoVDUq12ruJhtaWkJHx8fpKamitO0Wi1SU1Ph6+trxMqIiExfqziiAICIiAiEhoaib9++6N+/P1asWIE7d+5g0qRJxi6NiMiktZqgGDduHG7cuIFFixYhLy8PTz31FJKTk6FUKo1dmkmzsrLC4sWLa52KIyLDaA6fMZkg1OfeKCIiaq1axTUKIiJqOAYFERFJYlAQEZEkBgU1mIeHB1asWGHsMoiokTEoWgGZTCY5REZGNmi9p0+fxrRp0wxbLFEz1liftZp1JyUlGaxWfbSa22NbM819j1/eunUrFi1ahKysLHGanZ2d+FoQBFRXV8Pc/NH/NFxcXAxbKFEzp89nrTnhEUUroFKpxEGhUEAmk4njly5dgr29Pfbu3QsfHx9YWVnh6NGjyM7OxujRo6FUKmFnZ4d+/fph3759Out98NSTTCbDd999hzFjxsDW1hadO3fGrl27mnhviYxH6rOmUqmwZcsWdO/eHdbW1ujWrRvWrFkjLltRUYGwsDCo1WpYW1vD3d0dS5cuBXDvswYAY8aMgUwmE8ebCoOCAAAffPABPvvsM2RmZqJXr14oLS3F8OHDkZqairNnzyIwMBBBQUHIzc2VXM+SJUvw2muv4dy5cxg+fDhCQkJQWFjYRHtBZLoSEhKwaNEifPLJJ8jMzMSnn36KhQsXIj4+HgAQGxuLXbt2Ydu2bcjKykJCQoIYCKdPnwYAbNiwARqNRhxvMgZ5jjc1Gxs2bBAUCoU4fuDAAQGAkJSU9Mhle/ToIaxatUocd3d3F2JiYsRxAMKCBQvE8dLSUgGAsHfvXoPUTtScPPhZ+9vf/iZs3rxZp01UVJTg6+srCIIgvPPOO8KLL74oaLXaOtcHQEhMTGysciXxGgUBAPr27aszXlpaisjISOzZswcajQZVVVX466+/HnlE0atXL/F1mzZt4ODggOvXrzdKzUTNxZ07d5CdnY0pU6Zg6tSp4vSqqirxCa4TJ07ESy+9hK5duyIwMBAjR47E0KFDjVWyDgYFAUCtnrHee+89pKSk4Msvv4SnpydsbGzw6quvoqKiQnI9FhYWOuMymQxaI/U8RmQqSktLAQDffvstBgwYoDPPzMwMAPD0008jJycHe/fuxb59+/Daa6/B398f//rXv5q83gcxKKhOx44dw8SJEzFmzBgA9/6hX7582bhFETVTSqUSrq6u+OOPPxASEvLQdg4ODhg3bhzGjRuHV199FYGBgSgsLISTkxMsLCxQXV3dhFX/B4OC6tS5c2fs3LkTQUFBkMlkWLhwIY8MiB7DkiVLEB4eDoVCgcDAQJSXl+PMmTO4desWIiIiEB0dDbVajT59+kAul2P79u1QqVRip2keHh5ITU3FoEGDYGVlhbZt2zZZ7bzrieoUHR2Ntm3bYuDAgQgKCkJAQACefvppY5dF1Gy99dZb+O6777BhwwZ4e3tj8ODBiIuLQ6dOnQAA9vb2WLZsGfr27Yt+/frh8uXL+PHHHyGX3/uaXr58OVJSUuDm5oY+ffo0ae18zDgREUniEQUREUliUBARkSQGBRERSWJQEBGRJAYFERFJYlAQEZEkBgUREUliUBA1kcuXL0MmkyEjI8Pg666rb5DG6g2NXeC2PgwKajYmTpwodilpYWEBpVKJl156CevXr9f78SJxcXHioxEe15AhQ8S6rKys8MQTTyAoKAg7d+7Uaefm5gaNRoOePXs+cp36hkpjdEv7sPeIXeC2PgwKalYCAwOh0Whw+fJl7N27Fy+88ALeffddjBw5ElVVVUara+rUqdBoNMjOzsaOHTvg5eWF8ePH63yhmpmZQaVS1aub2fqqeZqvi4sLbG1tDbZeKU25LTIRRukFg6gBQkNDhdGjR9eanpqaKgAQvv32W3Ha8uXLhZ49ewq2trZChw4dhBkzZgi3b98WBOE/nTXdPyxevFgQBEHYuHGj4OPjI9jZ2QlKpVJ4/fXXhfz8fMm6Bg8eLLz77ru1pq9fv14AIKSkpAiCIAg5OTkCAOHs2bOCIAhCYWGh8MYbbwjOzs6CtbW14OnpKaxfv14QBKFWfYMHD9Z5Dz7++GNBrVYLHh4egiDU3YnUmjVrhMDAQMHa2lro1KmTsH37dnF+zXtw69YtcdrZs2cFAEJOTo7ke/Tgtv78809h1KhRQps2bQR7e3th7NixQl5enjh/8eLFQu/evYWNGzcK7u7ugoODgzBu3DihpKRE8n0l08EjCmr2XnzxRfTu3VvnVI9cLkdsbCwuXLiA+Ph47N+/H3PmzAEADBw4ECtWrICDgwM0Gg00Gg3ee+89AEBlZSWioqLw888/IykpCZcvX8bEiRMbVFdoaCjatm1b6xRUjYULF+LixYvYu3cvMjMz8fXXX8PZ2RkAcOrUKQDAvn37oNFodNaRmpqKrKwspKSkYPfu3Q/d/sKFCxEcHIyff/4ZISEhGD9+PDIzM+tVu9R7dD+tVovRo0ejsLAQhw4dQkpKCv744w+MGzdOp112djaSkpKwe/du7N69G4cOHcJnn31Wr1rI+PiYcWoRunXrhnPnzonjs2bNEl97eHjg448/xvTp07FmzRpYWlrqdHx/v8mTJ4uvn3zyScTGxqJfv34oLS2FnZ2dXjXJ5XJ06dLlof145Obmok+fPmLvgjX9IwP3Tu8AQLt27WrV2KZNG3z33XewtLSU3P7YsWPx1ltvAQCioqKQkpKCVatWYc2aNY+sXeo9ul9qaip++eUX5OTkwM3NDQCwceNG9OjRA6dPn0a/fv0A3AuUuLg42NvbAwDefPNNpKam4pNPPnlkLWR8PKKgFkEQBMhkMnF837598PPzwxNPPAF7e3u8+eabuHnzJsrKyiTXk56ejqCgIHTs2BH29vYYPHgwADyyC9j61nW/GTNmYMuWLXjqqacwZ84cHD9+vF7r9Pb2fmRIAICvr2+t8foeUdRXZmYm3NzcxJAAAC8vLzg6Oupsy8PDQwwJAFCr1ewitxlhUFCLkJmZKT7X//Llyxg5ciR69eqFHTt2ID09HatXrwYAya5c79y5g4CAADg4OCAhIQGnT59GYmLiI5d7mOrqavz2229iXQ8aNmwY/vzzT8yePRvXrl2Dn59fnad3HvRgt7UNUdPHgXBfLwOVlZWPvd6HYRe5zRuDgpq9/fv345dffkFwcDCAe0cFWq0Wy5cvxzPPPIMuXbrg2rVrOstYWlrW6lby0qVLuHnzJj777DM899xz6Nat22P91RsfH49bt26JddXFxcUFoaGh2LRpE1asWIFvvvlGrA/AY3V9eeLEiVrj3bt3F7cLABqNRpz/4K24db1HD+revTuuXLmCK1euiNMuXryIoqIieHl5Nbh2Mi28RkHNSnl5OfLy8lBdXY38/HwkJydj6dKlGDlyJCZMmAAA8PT0RGVlJVatWoWgoCAcO3YMa9eu1VmPh4cHSktLkZqait69e8PW1hYdO3aEpaUlVq1ahenTp+P8+fOIioqqV11lZWXIy8tDVVUVrl69isTERMTExGDGjBl44YUX6lxm0aJF8PHxQY8ePVBeXo7du3eLX+Tt27eHjY0NkpOT0aFDB1hbW0OhUOj1Xm3fvh19+/bFs88+i4SEBJw6dQrr1q0T3yM3NzdERkbik08+wa+//orly5c/8j168LZYf39/eHt7IyQkBCtWrEBVVRXefvttDB48WLz2Qi2Ake+6Iqq30NBQ8VZNc3NzwcXFRfD39xfWr18vVFdX67SNjo4W1Gq1YGNjIwQEBAgbN26sdTvo9OnThXbt2unc+rl582bBw8NDsLKyEnx9fYVdu3bp3NJal8GDB4t1WVpaCmq1Whg5cqSwc+dOnXYP3h4bFRUldO/eXbCxsRGcnJyE0aNHC3/88YfY/ttvvxXc3NwEuVxe6/bYB9V1e+zq1auFl156SbCyshI8PDyErVu36ixz9OhRwdvbW7C2thaee+45Yfv27eLtsVLvUUNvj71fTEyM4O7u/tD3lEwLu0IlIiJJvEZBRESSGBRERCSJQUFERJIYFEREJIlBQUREkhgUREQkiUFBRESSGBRERCSJQUFERJIYFEREJIlBQUREkhgUREQk6f8BLSLH/kn7gM8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "barWidth = 0.15\n",
    "fig = plt.subplots(figsize =(4,3)) \n",
    "\n",
    "spam = [N_spam, N_spam_test] \n",
    "legit = [len(train_labels)-N_spam, len(test_labels)-N_spam_test] \n",
    "\n",
    "br1 = np.arange(len(spam)) \n",
    "br2 = [x + barWidth for x in br1] \n",
    " \n",
    "plt.bar(br1, spam, color ='r', width = barWidth, \n",
    "        edgecolor ='grey', label ='Spam') \n",
    "plt.bar(br2, legit, color ='g', width = barWidth, \n",
    "        edgecolor ='grey', label ='Legit') \n",
    "\n",
    "plt.xlabel('Data Distribution', fontsize = 10) \n",
    "plt.ylabel('No of Emails', fontsize = 10) \n",
    "plt.xticks([r + barWidth for r in range(len(spam))], \n",
    "        ['Train', 'Test'])\n",
    " \n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982ebd0",
   "metadata": {},
   "source": [
    "## Feature selection using the information gain (IG) metric:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d75ef6",
   "metadata": {},
   "source": [
    "Information Gain/ Mutual Information:\n",
    "\n",
    "Mutual information is the amount of information that one random variable contains about another. In other words, it’s a measure of their mutual dependence.\n",
    "\n",
    "The two random variables in the above definition are Term ‘T’ and Class ‘C’, where t ∈ T and c ∈ C {Spam, Legit}. \n",
    "\n",
    "$$\n",
    "I(t\\in \\{0, 1\\}, c \\in \\{0, 1\\}) = \\frac{N_{11}}{N}\\log_2\\frac{NN_{11}}{N_{1*}N_{*1}}+ \\frac{N_{01}} {N}\\log_2\\frac{NN_{01}}{N_{0*}N_{*1}} + \\frac{N_{10}}{N}\\log_2\\frac{NN_{10}}{N_{1*}N_{*0}} + \\frac{N_{00}}{N}\\log_2\\frac{NN_{00}}{N_{0*}N_{*0}} \n",
    "$$\n",
    "\n",
    "- $N_{11}$ is the number of emails that contain the term 't' and belong to class 'spam' \n",
    "- $N_{10}$ is the number of emails that contain term 't' but do not belong to class 'spam'\n",
    "- $N_{01}$ is the count of emails classified as 'spam', where term 't' is absent\n",
    "- $N_{00}$ is the count of the emails that neither have the term 't' , nor belong to 'spam' \n",
    "\n",
    "$$\n",
    "N_{1*} = N_{10} + N_{11}\\\\\n",
    "N_{*1} = N_{01} + N_{11} \\\\\n",
    "N_{0*} = N_{01} + N_{00} \\\\ \n",
    "N_{*0} = N_{10} + N_{00}\n",
    "$$\n",
    "\n",
    "\n",
    "#### References: [Mutual Information Calculation](https://nlp.stanford.edu/IR-book/html/htmledition/mutual-information-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/mutual-information-1.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b01ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_extraction():\n",
    "    def __init__(self, emails, labels, no_of_features, is_binary = True):\n",
    "        self.no_of_features = no_of_features \n",
    "        self.raw_emails = emails\n",
    "        self.train_labels = labels\n",
    "        self.no_of_samples = len(emails)\n",
    "        self.N_spam = sum(self.train_labels)\n",
    "        self.is_binary = is_binary\n",
    "        self.vocab = None\n",
    "        self.processed_text = None\n",
    "        self.X_train = None\n",
    "        self.feature_matrix = None\n",
    "        self.extracted_features = None\n",
    "        \n",
    "    def remove_punctuation(self, string):\n",
    "        result = ''.join(filter(lambda x: x.isalpha() or x.isdigit() or x.isspace(), string))\n",
    "        return result\n",
    "        \n",
    "    def preprocessing(self, emails):\n",
    "        filtered_list = emails.copy()\n",
    "        for i in range(len(emails)):\n",
    "            filtered_list[i] = (self.remove_punctuation(emails[i]))\n",
    "        return filtered_list\n",
    "    \n",
    "    def get_feature_matrix(self, train=True):\n",
    "        self.processed_text = self.preprocessing(self.raw_emails)\n",
    "        if(train==True):\n",
    "            self.vectorizer = CountVectorizer(binary=self.is_binary)\n",
    "            vec = self.vectorizer.fit_transform(self.processed_text)\n",
    "            vocab = self.vectorizer.vocabulary_\n",
    "            self.vocab = dict((v,k) for k,v in vocab.items())\n",
    "            self.X_train = vec.toarray()            \n",
    "            \n",
    "        X_train_spam = []\n",
    "        X_train_legit = []\n",
    "        for i in range(len(self.processed_text)):\n",
    "            if self.train_labels[i]==1:\n",
    "                X_train_spam.append(self.X_train[i])\n",
    "            else:\n",
    "                X_train_legit.append(self.X_train[i])\n",
    "\n",
    "        self.feature_matrix = [np.sum(np.array(X_train_spam), axis = 0), np.sum(np.array(X_train_legit), axis = 0)]  \n",
    "    \n",
    "    def calculate_mutual_info(self, feature): \n",
    "        N11 = self.feature_matrix[0][feature]\n",
    "        N10 = self.feature_matrix[1][feature]\n",
    "        N01 = (self.N_spam - N11)\n",
    "        N00 = self.no_of_samples - (N11+N01+N10)\n",
    "        N1dot = N11+N10\n",
    "        Ndot1 = N_spam\n",
    "        N0dot = N01+N00\n",
    "        Ndot0 = self.no_of_samples - self.N_spam\n",
    "        keys = [N11, N10, N01, N00]\n",
    "        values = [N1dot*Ndot1, N1dot*Ndot0, N0dot*Ndot1, N0dot*Ndot0]\n",
    "        mi = 0\n",
    "        for i in range(4):\n",
    "            if keys[i]==0:\n",
    "                mi+=0\n",
    "            else:\n",
    "                mi+= (keys[i]/self.no_of_samples)*np.log2(keys[i]*self.no_of_samples/values[i])\n",
    "        return mi \n",
    "    \n",
    "    def topKfeatures(self):\n",
    "        self.get_feature_matrix()\n",
    "        IG = []\n",
    "        for i in range(len(self.vocab)):\n",
    "            IG.append(self.calculate_mutual_info(i))\n",
    "        sorted_index = np.argsort(np.array(IG))[::-1][:self.no_of_features]\n",
    "        self.extracted_features = {s: self.vocab[s] for s in sorted_index}\n",
    "        return self.extracted_features\n",
    "    \n",
    "    def embedding(self, X_):\n",
    "        X = []\n",
    "        for i in range(len(X_)):\n",
    "            X.append([X_[i][k] for k in self.extracted_features.keys()])\n",
    "        return np.array(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884cf7aa",
   "metadata": {},
   "source": [
    "#### Task - 1: A list of the top-10 words identified from Part (1) above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b740a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Selected Features: \n",
      "['language', 'remove', 'free', 'linguistic', 'university', 'money', 'click', 'market', 'our', 'business']\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "fe = Feature_extraction(train_emails, train_labels, N)\n",
    "fe.topKfeatures()\n",
    "print(\"Top 10 Selected Features: \")\n",
    "print(list(fe.extracted_features.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d16e6",
   "metadata": {},
   "source": [
    "##### NOTE:\n",
    "- The features with highest information gain are considered, implies the words that most influence the classification output are considered.\n",
    "- Feature selection reduces the number of features to be considered for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be0364",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes with Binary Features:\n",
    "\n",
    "- Let x =($x_1, x_2 ....,x_M$) denote M features for an email X.\n",
    "- Email can either be {1 - spam, 0 - Legit}\n",
    "- $x_i$ is either 1 or 0. 0 if the feature is not in the email, 1 if the feature is present.\n",
    "#### Step - 1: Bayes Rule:\n",
    "\n",
    "$$\n",
    "P(spam|x) = \\frac{P(x|spam)*P(spam)}{P(x)}\n",
    "$$\n",
    "Assuming all term occurences are independent,\n",
    "$$\n",
    "P(x_1, x_2, x_3 ...,x_M|spam) = P(x_1|spam)*P(x_2|spam)*.... P(x_M|spam) \\\\\n",
    "P(x_1 = 1|spam) = p_{i,s} = \\frac{\\text{#Spam emails that contain term i}}{\\text{#Spam emails}}\n",
    "$$\n",
    "#### Step - 2: Laplacian Smoothing, find Likelihood/ Conditional probabilities\n",
    "$$\n",
    "P(x_1 = 1|spam) = p_{i,s} = \\frac{\\text{#Spam emails that contain term i + 1}}{\\text{#Spam emails + 2}}\\\\\n",
    "P(x_1 = 0 |spam) = 1 - p_{i,s} \\\\ \n",
    "P(x_1, x_2,...x_M|spam) = \\prod_{i=1}^M p_{i,s}^{x_i} (1-p_{i,s})^{1-x_i}\n",
    "$$\n",
    "\n",
    "#### Step - 3: Compare P(spam|x) vs P(legit|x):\n",
    "\n",
    "Applying log to the Bayes theorem, \n",
    "$$\n",
    "\\log(P(spam|x) = \\log P(x|spam) + \\log P(spam) - \\log P(x) \\\\\n",
    "\\log(P(legit|x) = \\log P(x|legit) + \\log P(legit) - \\log P(x) \n",
    "$$\n",
    "\n",
    "\n",
    "If log P(spam|x) > log(P(legit|x) predicted label is spam, else legit. (**Note**: log P(x) cann be ignored, it is present in both the equations)\n",
    "\n",
    "\n",
    "P(spam|x) > threshold => predicted_output = 1 (spam)\n",
    "\n",
    "#### Step - 4: Predict Step:\n",
    "\n",
    "After finding the prior, and likelihood, now we have to find the posterior probabilities for each of the mail in the test dataset. Perform Step3 and determine the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68fa4243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BernoulliNBClassifier(Feature_extraction):    \n",
    "    def train(self, mail):\n",
    "        log_px_spam = 0\n",
    "        log_px_legit = 0\n",
    "        for i in self.extracted_features.keys():\n",
    "            p_is = (self.feature_matrix[0][i]+1)/(self.N_spam+2)\n",
    "            p_il = (self.feature_matrix[1][i]+1)/(self.no_of_samples-self.N_spam+2)\n",
    "            if self.extracted_features[i] in mail:\n",
    "                log_px_spam = log_px_spam+np.log(p_is)\n",
    "                log_px_legit = log_px_legit+np.log(p_il)\n",
    "\n",
    "            else:\n",
    "                log_px_spam = log_px_spam+np.log(1-p_is)\n",
    "                log_px_legit = log_px_legit+np.log(1-p_il)\n",
    "\n",
    "        log_p_spam = np.log(self.N_spam/self.no_of_samples)\n",
    "        log_p_legit = np.log(1-(self.N_spam/self.no_of_samples))\n",
    "        log_pspam_x = log_p_spam+log_px_spam\n",
    "        log_plegit_x = log_p_legit+log_px_legit\n",
    "        return 1 if(log_pspam_x>log_plegit_x) else 0\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        self.topKfeatures()\n",
    "        predicted_labels = []\n",
    "        processed_test = self.preprocessing(X_test)\n",
    "        for mail in processed_test:\n",
    "            predicted_labels.append(self.train(mail.split(' ')))\n",
    "        return predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d73bc3",
   "metadata": {},
   "source": [
    "### Performance Metrics: \n",
    "\n",
    "Recall and Precision are two important metrics for evaluating the performance of classification models, particularly in the context of binary classification. These metrics have a range between 0 and 1.\n",
    "\n",
    "**Precision**: Precision measures the accuracy of positive predictions made by the model. It is the ratio of true positive instances to the total number of positive predictions made by the model (true positives + false positives). The range of precision is also between 0 and 1, where 0 indicates that all positive predictions are incorrect, and 1 indicates that all positive predictions are correct.\n",
    "\n",
    "**Recall/ TPR (True Positive Rate)**:  Recall measures the ability of a model to identify all relevant instances in the dataset. It is the ratio of true positive (correctly predicted positive) instances to the total number of actual positive instances. The range of recall is between 0 and 1, where 0 indicates no correct positive predictions, and 1 indicates all positive instances were correctly predicted.\n",
    "\n",
    "**Accuracy**:(Number of Correct Predictions) / (Total Number of Predictions). While accuracy is a valuable metric, it may not be suitable when there is class imbalance or when the cost of misclassifying specific classes is significantly different. In those cases, class-specific metrics like Precision and Recall are more informative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae014bc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Performance_metrics():\n",
    "    def __init__(self, true_labels, predicted_labels):\n",
    "        self.true_labels = true_labels\n",
    "        self.predicted_labels = predicted_labels\n",
    "        self.TP = 0\n",
    "        self.FP = 0\n",
    "        self.TN = 0\n",
    "        self.FN = 0\n",
    "        for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
    "            if true_label == 1 and predicted_label == 1:\n",
    "                self.TP += 1\n",
    "            elif true_label == 0 and predicted_label == 1:\n",
    "                self.FP += 1\n",
    "            elif true_label == 0 and predicted_label == 0:\n",
    "                self.TN += 1\n",
    "            elif true_label == 1 and predicted_label == 0:\n",
    "                self.FN += 1\n",
    "        \n",
    "    def SpamPrecision(self):\n",
    "        return self.TP / (self.TP + self.FP)\n",
    "        \n",
    "    def SpamRecall(self):\n",
    "        return self.TP / (self.TP + self.FN)\n",
    "    \n",
    "    def Accuracy(self):\n",
    "        return (self.TP + self.TN)/(self.TP + self.TN + self.FP + self.FN) \n",
    "    \n",
    "    def Print_Scores(self):\n",
    "        print(f\"[True Positives, True Negatives]: [{self.TP}, {self.TN}]\")\n",
    "        print(f\"[False Positives, False Negatives]: [{self.FP}, {self.FN}]\")\n",
    "        print(f\"Accuracy: {self.Accuracy():.3f}\")\n",
    "        print(f\"Spam Precision: {self.SpamPrecision():.3f}\")\n",
    "        print(f\"Spam Recall: {self.SpamRecall():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e23912",
   "metadata": {},
   "source": [
    "### Comparing with SKlearn library function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "259f66b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       242\n",
      "           1       1.00      0.67      0.80        49\n",
      "\n",
      "    accuracy                           0.95       291\n",
      "   macro avg       0.97      0.84      0.89       291\n",
      "weighted avg       0.95      0.95      0.94       291\n",
      "\n",
      "****************\n",
      " Confusion Matrix: \n",
      "[[242   0]\n",
      " [ 16  33]]\n"
     ]
    }
   ],
   "source": [
    "### Implemented Classifier\n",
    "\n",
    "clf = BernoulliNBClassifier(train_emails, train_labels, 100)\n",
    "predicted_labels = clf.predict(test_emails)\n",
    "print(classification_report(test_labels, predicted_labels))\n",
    "print(\"****************\\n Confusion Matrix: \")\n",
    "print(confusion_matrix(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "452f0272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       242\n",
      "           1       1.00      0.67      0.80        49\n",
      "\n",
      "    accuracy                           0.95       291\n",
      "   macro avg       0.97      0.84      0.89       291\n",
      "weighted avg       0.95      0.95      0.94       291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Library Function\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Feature Selection\n",
    "fe = Feature_extraction(train_emails, train_labels, 100)\n",
    "fe.topKfeatures()\n",
    "X_ = fe.embedding(fe.X_train)\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(X_, train_labels)\n",
    "test_pred = model.predict(fe.embedding(fe.vectorizer.transform(fe.preprocessing(test_emails)).toarray()))\n",
    "print(classification_report(test_labels, test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f00ecf",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "- Both the implemented BernoulliNB and scikit learn BernoulliNB give the same performance after feature selection using Mutual Information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10382653",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes with Binary Features\n",
    "\n",
    "This is similar to Bernoulli naive bayes except \n",
    "- Multinomial model ignores negative evidence\n",
    "- $p_{i, s}$ is estimated differently\n",
    "- $\\bar{x_i}$ = 1 if term i is in mail x, else 0 (Binary Features)\n",
    "$$\n",
    " p_{i,s} = \\frac{\\text{1 + # occurences if term i in spam}}{\\text{M}+\\sum_{i=1}^{M}\\text{# occurences of term i in spam}} \\\\\n",
    " p(\\bar{x}|spam) = D! \\prod_{i=1}^{M} p_{i,s}^\\bar{x_i}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d7373db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNBClassifierBF(Feature_extraction):    \n",
    "    def train(self, mail):\n",
    "        log_px_spam = 0\n",
    "        log_px_legit = 0\n",
    "        M = np.shape(self.feature_matrix)[1]\n",
    "        [den1, den2] = np.sum(self.feature_matrix, axis=1)\n",
    "        for i in self.extracted_features.keys():\n",
    "            p_is = (self.feature_matrix[0][i]+1)/(den1 + M)\n",
    "            p_il = (self.feature_matrix[1][i]+1)/(den2 + M)\n",
    "            if self.extracted_features[i] in mail:\n",
    "                log_px_spam = log_px_spam + np.log(p_is)\n",
    "                log_px_legit = log_px_legit + np.log(p_il)\n",
    "\n",
    "        log_p_spam = np.log(self.N_spam/self.no_of_samples)\n",
    "        log_p_legit = np.log(1-(self.N_spam/self.no_of_samples))\n",
    "        log_pspam_x = log_p_spam+log_px_spam\n",
    "        log_plegit_x = log_p_legit+log_px_legit\n",
    "        return 1 if(log_pspam_x>log_plegit_x) else 0\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        self.topKfeatures()\n",
    "        predicted_labels = []\n",
    "        processed_test = self.preprocessing(X_test)\n",
    "        for mail in processed_test:\n",
    "            predicted_labels.append(self.train(mail.split(' ')))\n",
    "        return predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7da740",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes with TF\n",
    "\n",
    "This is similar to Multinomial Naive Bayes with Binary Features except the features now are not binary anymore, they are the term frequencies.\n",
    "- $x_i$ is the ith term frequency in the mail X\n",
    "\n",
    "$$\n",
    " p_{i,s} = \\frac{\\text{1 + # occurences if term i in spam}}{\\text{M}+\\sum_{i=1}^{M}\\text{# occurences of term i in spam}} \\\\\n",
    " p(x|spam) = D! \\prod_{i=1}^{M} p_{i,s}^{x_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5260859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNBClassifierTF(Feature_extraction):    \n",
    "    def train(self, mail):\n",
    "        log_px_spam = 0\n",
    "        log_px_legit = 0\n",
    "        M = np.shape(self.feature_matrix)[1]\n",
    "        [den1, den2] = np.sum(self.feature_matrix, axis=1)\n",
    "        for i in self.extracted_features.keys():\n",
    "            p_is = (self.feature_matrix[0][i]+1)/(den1 + M)\n",
    "            p_il = (self.feature_matrix[1][i]+1)/(den2 + M)\n",
    "            if self.extracted_features[i] in mail:\n",
    "                x_i = mail.count(self.extracted_features[i])\n",
    "                log_px_spam = log_px_spam + x_i*np.log(p_is)\n",
    "                log_px_legit = log_px_legit + x_i*np.log(p_il)\n",
    "\n",
    "        log_p_spam = np.log(self.N_spam/self.no_of_samples)\n",
    "        log_p_legit = np.log(1-(self.N_spam/self.no_of_samples))\n",
    "        log_pspam_x = log_p_spam+log_px_spam\n",
    "        log_plegit_x = log_p_legit+log_px_legit\n",
    "        return 1 if(log_pspam_x>log_plegit_x) else 0\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        self.topKfeatures()\n",
    "        predicted_labels = []\n",
    "        processed_test = self.preprocessing(X_test)\n",
    "        for mail in processed_test:\n",
    "            predicted_labels.append(self.train(mail.split(' ')))\n",
    "        return predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe9d95c",
   "metadata": {},
   "source": [
    "#### Task - 2:  A list of spam precision and spam recall values for each of the three classifiers for N = {10, 100, 1000}. That is, your list should have 9 rows, one for each classifier and N combination.\n",
    "#### Results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "102f75e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "Model:  <class '__main__.BernoulliNBClassifier'>\n",
      "-------------------------------------\n",
      "For Number of features: 10\n",
      "[True Positives, True Negatives]: [40, 237]\n",
      "[False Positives, False Negatives]: [5, 9]\n",
      "Accuracy: 0.952\n",
      "Spam Precision: 0.889\n",
      "Spam Recall: 0.816\n",
      "Latency of Classifier: 1.5740 sec\n",
      "-------------------------------------\n",
      "For Number of features: 100\n",
      "[True Positives, True Negatives]: [33, 242]\n",
      "[False Positives, False Negatives]: [0, 16]\n",
      "Accuracy: 0.945\n",
      "Spam Precision: 1.000\n",
      "Spam Recall: 0.673\n",
      "Latency of Classifier: 1.7613 sec\n",
      "-------------------------------------\n",
      "For Number of features: 1000\n",
      "[True Positives, True Negatives]: [28, 242]\n",
      "[False Positives, False Negatives]: [0, 21]\n",
      "Accuracy: 0.928\n",
      "Spam Precision: 1.000\n",
      "Spam Recall: 0.571\n",
      "Latency of Classifier: 3.3686 sec\n",
      "***************************\n",
      "Model:  <class '__main__.MultinomialNBClassifierBF'>\n",
      "-------------------------------------\n",
      "For Number of features: 10\n",
      "[True Positives, True Negatives]: [40, 237]\n",
      "[False Positives, False Negatives]: [5, 9]\n",
      "Accuracy: 0.952\n",
      "Spam Precision: 0.889\n",
      "Spam Recall: 0.816\n",
      "Latency of Classifier: 1.5860 sec\n",
      "-------------------------------------\n",
      "For Number of features: 100\n",
      "[True Positives, True Negatives]: [46, 240]\n",
      "[False Positives, False Negatives]: [2, 3]\n",
      "Accuracy: 0.983\n",
      "Spam Precision: 0.958\n",
      "Spam Recall: 0.939\n",
      "Latency of Classifier: 1.6972 sec\n",
      "-------------------------------------\n",
      "For Number of features: 1000\n",
      "[True Positives, True Negatives]: [46, 242]\n",
      "[False Positives, False Negatives]: [0, 3]\n",
      "Accuracy: 0.990\n",
      "Spam Precision: 1.000\n",
      "Spam Recall: 0.939\n",
      "Latency of Classifier: 2.9772 sec\n",
      "***************************\n",
      "Model:  <class '__main__.MultinomialNBClassifierTF'>\n",
      "-------------------------------------\n",
      "For Number of features: 10\n",
      "[True Positives, True Negatives]: [42, 237]\n",
      "[False Positives, False Negatives]: [5, 7]\n",
      "Accuracy: 0.959\n",
      "Spam Precision: 0.894\n",
      "Spam Recall: 0.857\n",
      "Latency of Classifier: 1.5198 sec\n",
      "-------------------------------------\n",
      "For Number of features: 100\n",
      "[True Positives, True Negatives]: [46, 241]\n",
      "[False Positives, False Negatives]: [1, 3]\n",
      "Accuracy: 0.986\n",
      "Spam Precision: 0.979\n",
      "Spam Recall: 0.939\n",
      "Latency of Classifier: 1.7704 sec\n",
      "-------------------------------------\n",
      "For Number of features: 1000\n",
      "[True Positives, True Negatives]: [46, 242]\n",
      "[False Positives, False Negatives]: [0, 3]\n",
      "Accuracy: 0.990\n",
      "Spam Precision: 1.000\n",
      "Spam Recall: 0.939\n",
      "Latency of Classifier: 3.0360 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def ScoresfordifferentN(model, no_of_features, train_emails, train_labels, test_emails, test_labels, list_precision_recall):\n",
    "    for i in no_of_features:\n",
    "        print('-------------------------------------')\n",
    "        print(f\"For Number of features: {i}\")\n",
    "        start = time.time()\n",
    "        clf = model(train_emails, train_labels, i)\n",
    "        predicted_labels = clf.predict(test_emails)\n",
    "        end = time.time()\n",
    "        pm = Performance_metrics(test_labels, predicted_labels)\n",
    "        pm.Print_Scores()\n",
    "        list_precision_recall.append([pm.SpamPrecision(), pm.SpamRecall()])\n",
    "        print(f\"Latency of Classifier: {end-start:.4f} sec\")\n",
    "        \n",
    "list_precision_recall = []\n",
    "no_of_features = [10, 100, 1000]\n",
    "for model in [BernoulliNBClassifier, MultinomialNBClassifierBF, MultinomialNBClassifierTF]:\n",
    "    print(\"***************************\\nModel: \",str(model))\n",
    "    ScoresfordifferentN(model, no_of_features, train_emails, train_labels, test_emails, test_labels, list_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baa026bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Spam Precisions and Recall for different Classifiers and different Number of Features: [[0.8888888888888888, 0.8163265306122449], [1.0, 0.673469387755102], [1.0, 0.5714285714285714], [0.8888888888888888, 0.8163265306122449], [0.9583333333333334, 0.9387755102040817], [1.0, 0.9387755102040817], [0.8936170212765957, 0.8571428571428571], [0.9787234042553191, 0.9387755102040817], [1.0, 0.9387755102040817]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"List of Spam Precisions and Recall for different Classifiers and different Number of Features: {list_precision_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5db75",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "\n",
    "- MultinomialNBClassifierBF and MultinomialNBClassifierTF classifiers have almost similar performance/ accuracy\n",
    "\n",
    "- MultinomialNBClassifierBF is performing better than BernoulliNBClassifierBF\n",
    "\n",
    "- We can observe a high precision (close to 1 for almost all the models) means that the model makes very few false positive predictions, which is important when false positives are costly (e.g., spam email classification).\n",
    "\n",
    "- A high recall (close to 1) means that the model is good at capturing almost all positive instances.\n",
    "\n",
    "- We can adjust the decision threshold of your model to increase one metric at the expense of the other. The choice of the threshold depends on your specific goals and the consequences of false positives and false negatives in your application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec3103f",
   "metadata": {},
   "source": [
    "## SVM Spam Filtering:\n",
    "\n",
    "### Methodology: \n",
    "- Feature Selection: Using Information Gain/ Mutual Information (same as above) for feature selection. Top 10 features are used as features. CountVectorizer (Term Frequency) will convert tokens to embedddings.\n",
    "\n",
    "- Now implement the SVM classifier with different kernels and different Hyperparameters. \n",
    "\n",
    "**Loss:** \n",
    "The Dual Lagrangian loss function which we are trying to maximize is:\n",
    "$$\n",
    "L_{dual} = \\sum_{}\\alpha_i – \\frac{1}{2} \\sum_{i}\\sum_{j} \\alpha_i\\alpha_j y_i y_j K(x_i, x_j)\n",
    "$$\n",
    "\n",
    "**Gradient:**\n",
    "$$\n",
    "\\frac{\\delta L_{dual}}{\\delta \\alpha_k} = 1 - y_k \\sum_{} \\alpha_j y_j K(x_j, x_k)\n",
    "$$\n",
    "\n",
    "K(xi, xj) is our Kernal function which could be linear, polynomial or gaussian(rbf).\n",
    "\n",
    "- For Polynomial: $(c + X_1 X_2)^{degree}$\n",
    "- For Gaussian (RBF): $e^{(-1/\\sigma^2)||X_1-X_2||^2}$\n",
    "\n",
    "**Updates:**\n",
    "$$\n",
    "\\alpha_k = \\alpha_k + \\eta \\frac{\\delta L_{dual}}{\\delta \\alpha_k}\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "**Prediction:** \n",
    "$$\n",
    "\\hat{y} = \\text{sign}(\\sum_{}\\alpha_i y_i k(x_i, x_i) + b)\n",
    "$$\n",
    "- Tune the classifier using k-fold cross validation (3 fold). 1 folder is used for testing. Rest of the 9 folders are split into Train and Validation sets ( 6 + 3 = 9). This way, we can find the average precision across different folds. \n",
    "\n",
    "- Since, **Precision** is an important metric in case of spam filtering. We want the hyperparameters combination that has maximum precision.\n",
    "\n",
    "\n",
    "#### References: \n",
    "- [Kernel SVM](https://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-kernel-svm/)\n",
    "\n",
    "- [Training Algorithm SVM](https://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-training-algorithms/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e32fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_selection(Feature_extraction):    \n",
    "    def get_Xfeatures(self, X_):\n",
    "        X = []\n",
    "        for i in range(len(X_)):\n",
    "            X.append([X_[i][k] for k in self.extracted_features.keys()])\n",
    "        return np.array(X)\n",
    "    \n",
    "    def fit(self):\n",
    "        self.topKfeatures()\n",
    "        self.countvectorizer = CountVectorizer()\n",
    "        vec = self.countvectorizer.fit_transform(self.processed_text)\n",
    "        Xcounter = vec.toarray()\n",
    "        return self.get_Xfeatures(Xcounter)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self.get_Xfeatures(self.countvectorizer.transform(self.preprocessing(X)).toarray())\n",
    "\n",
    "\n",
    "fs = Feature_selection(train_emails, train_labels, 10)\n",
    "X_train = fs.fit()\n",
    "X_test = fs.transform(test_emails)\n",
    "Y_train = train_labels\n",
    "Y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "967be2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_Fold_DataLoader(train_indices, val_indices):\n",
    "    train_emails = []\n",
    "    train_labels = []\n",
    "    val_emails = []\n",
    "    val_labels = []\n",
    "    trainfolder = ['part'+str(i) for i in train_indices]\n",
    "    valfolder = ['part'+str(i) for i in val_indices]\n",
    "    for folder in trainfolder:\n",
    "        load_from_folder(folder, train_emails, train_labels)\n",
    "\n",
    "    for folder in valfolder:\n",
    "        load_from_folder(folder, val_emails, val_labels)\n",
    "\n",
    "    return train_emails, train_labels, val_emails, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "849fba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_poly:\n",
    "    def __init__(self, degree, epoches=1000, learning_rate= 0.1):\n",
    "        self.alpha = None\n",
    "        self.b = 0\n",
    "        self.degree = degree\n",
    "        self.c = 1\n",
    "        self.C = 1\n",
    "        self.epoches = epoches\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def kernel(self,X,Y):\n",
    "        return (self.c + X.dot(Y.T))**self.degree \n",
    " \n",
    "    def train(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.alpha = np.random.random(X.shape[0])\n",
    "        self.b = 0\n",
    "        self.ones = np.ones(X.shape[0]) \n",
    "        y_mul_kernal = np.outer(y, y) * self.kernel(X, X) \n",
    "\n",
    "        for i in range(self.epoches):\n",
    "            gradient = self.ones - y_mul_kernal.dot(self.alpha) \n",
    "            self.alpha += self.learning_rate * gradient \n",
    "            self.alpha[self.alpha > self.C] = self.C \n",
    "            self.alpha[self.alpha < 0] = 0 \n",
    "\n",
    "            loss = np.sum(self.alpha) - 0.5 * np.sum(np.outer(self.alpha, self.alpha) * y_mul_kernal) \n",
    "            \n",
    "        alpha_index = np.where((self.alpha) > 0 & (self.alpha < self.C))[0]\n",
    "        \n",
    "        b_list = []        \n",
    "        for index in alpha_index:\n",
    "            b_list.append(y[index] - (self.alpha * y).dot(self.kernel(X, X[index])))\n",
    "\n",
    "        self.b = np.mean(b_list)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.sign((self.alpha * self.y).dot(self.kernel(self.X, X)) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71c4096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_rbf:\n",
    "    def __init__(self, sigma, epoches=1000, learning_rate= 0.1):\n",
    "        self.alpha = None\n",
    "        self.b = 0\n",
    "        self.c = 1\n",
    "        self.C = 1\n",
    "        self.sigma = sigma\n",
    "        self.epoches = epoches\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def kernel(self, X,Y):\n",
    "        return np.exp(-(1 / self.sigma ** 2) * np.linalg.norm(X[:, np.newaxis] - Y[np.newaxis, :], axis=2) ** 2)\n",
    "    \n",
    "    def train(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.alpha = np.random.random(X.shape[0])\n",
    "        self.b = 0\n",
    "        self.ones = np.ones(X.shape[0]) \n",
    "        y_mul_kernal = np.outer(y, y) * self.kernel(X, X) \n",
    "\n",
    "        for i in range(self.epoches):\n",
    "            gradient = self.ones - y_mul_kernal.dot(self.alpha) \n",
    "\n",
    "            self.alpha += self.learning_rate * gradient \n",
    "            self.alpha[self.alpha > self.C] = self.C \n",
    "            self.alpha[self.alpha < 0] = 0 \n",
    "\n",
    "            loss = np.sum(self.alpha) - 0.5 * np.sum(np.outer(self.alpha, self.alpha) * y_mul_kernal) # ∑αi – (1/2) ∑i ∑j αi αj yi yj K(xi, xj)\n",
    "            \n",
    "        alpha_index = np.where((self.alpha) > 0 & (self.alpha < self.C))[0]\n",
    "        \n",
    "        b_list = []        \n",
    "        for index in alpha_index:\n",
    "            b_list.append(y[index] - (self.alpha * y).dot(self.kernel(X, X[index])))\n",
    "\n",
    "        self.b = np.mean(b_list) \n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.sign((self.alpha * self.y).dot(self.kernel(self.X, X)) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da84919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_fold_cross_validation(train_set, val_set, lr, kernel, param):\n",
    "    average_accuracy = average_precision = average_recall = 0\n",
    "    for i in range(len(train_set)):\n",
    "        train_emails, train_labels, val_emails, val_labels = K_Fold_DataLoader(train_set[i], val_set[i])\n",
    "        X_train = fs.transform(train_emails)\n",
    "        X_val = fs.transform(val_emails)\n",
    "        Y_train = train_labels\n",
    "        Y_val = val_labels\n",
    "        if(kernel == 'poly'):\n",
    "            clf = SVM_poly(degree=param,learning_rate = lr)\n",
    "        if(kernel == 'rbf'):\n",
    "            clf = SVM_rbf(sigma = param, learning_rate = lr)\n",
    "        clf.train(X_train, Y_train)\n",
    "        predicted_labels = clf.predict(X_test)\n",
    "        predicted = np.where(predicted_labels == -1, 0, 1)\n",
    "        print(\"----------------\\nFor the Fold: \", i+1)\n",
    "        pm = Performance_metrics(Y_train, predicted)\n",
    "        average_precision += pm.SpamPrecision()\n",
    "        average_recall += pm.SpamRecall()\n",
    "        average_accuracy += pm.Accuracy()\n",
    "        print(f\"Validation Recall: {pm.SpamRecall():.3f}\")\n",
    "        print(f\"Validation Precision: {pm.SpamPrecision():.3f}\")\n",
    "        print(f\"Validation Accuracy: {pm.Accuracy():.3f}\")\n",
    "    return average_precision/3., average_recall/3., average_accuracy/3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad4acfbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*##########################################\n",
      " For SVM Kernel: rbf\n",
      " Sigma:0.1 \n",
      " Learning rate : 0.1\n",
      "----------------\n",
      "For the Fold:  1\n",
      "Validation Recall: 0.041\n",
      "Validation Precision: 0.061\n",
      "Validation Accuracy: 0.732\n",
      "----------------\n",
      "For the Fold:  2\n",
      "Validation Recall: 0.041\n",
      "Validation Precision: 0.054\n",
      "Validation Accuracy: 0.718\n",
      "----------------\n",
      "For the Fold:  3\n",
      "Validation Recall: 0.083\n",
      "Validation Precision: 0.111\n",
      "Validation Accuracy: 0.739\n",
      "*****************\n",
      "Average Validation Precision: 0.075\n",
      "\n",
      "Average Validation Recall: 0.055\n",
      "\n",
      "Average Validation Accuracy: 0.730\n",
      "*##########################################\n",
      " For SVM Kernel: rbf\n",
      " Sigma:1 \n",
      " Learning rate : 0.1\n",
      "----------------\n",
      "For the Fold:  1\n",
      "Validation Recall: 0.184\n",
      "Validation Precision: 0.130\n",
      "Validation Accuracy: 0.656\n",
      "----------------\n",
      "For the Fold:  2\n",
      "Validation Recall: 0.163\n",
      "Validation Precision: 0.125\n",
      "Validation Accuracy: 0.667\n",
      "----------------\n",
      "For the Fold:  3\n",
      "Validation Recall: 0.188\n",
      "Validation Precision: 0.129\n",
      "Validation Accuracy: 0.656\n",
      "*****************\n",
      "Average Validation Precision: 0.128\n",
      "\n",
      "Average Validation Recall: 0.178\n",
      "\n",
      "Average Validation Accuracy: 0.660\n",
      "*##########################################\n",
      " For SVM Kernel: rbf\n",
      " Sigma:10 \n",
      " Learning rate : 0.1\n",
      "----------------\n",
      "For the Fold:  1\n",
      "Validation Recall: 0.510\n",
      "Validation Precision: 0.150\n",
      "Validation Accuracy: 0.430\n",
      "----------------\n",
      "For the Fold:  2\n",
      "Validation Recall: 0.510\n",
      "Validation Precision: 0.152\n",
      "Validation Accuracy: 0.436\n",
      "----------------\n",
      "For the Fold:  3\n",
      "Validation Recall: 0.604\n",
      "Validation Precision: 0.169\n",
      "Validation Accuracy: 0.443\n",
      "*****************\n",
      "Average Validation Precision: 0.157\n",
      "\n",
      "Average Validation Recall: 0.542\n",
      "\n",
      "Average Validation Accuracy: 0.436\n",
      "*##########################################\n",
      " For SVM Kernel: poly\n",
      " Degree:2 \n",
      " Learning rate : 0.1\n",
      "----------------\n",
      "For the Fold:  1\n",
      "Validation Recall: 0.082\n",
      "Validation Precision: 0.444\n",
      "Validation Accuracy: 0.828\n",
      "----------------\n",
      "For the Fold:  2\n",
      "Validation Recall: 0.082\n",
      "Validation Precision: 0.267\n",
      "Validation Accuracy: 0.808\n",
      "----------------\n",
      "For the Fold:  3\n",
      "Validation Recall: 0.083\n",
      "Validation Precision: 0.286\n",
      "Validation Accuracy: 0.814\n",
      "*****************\n",
      "Average Validation Precision: 0.332\n",
      "\n",
      "Average Validation Recall: 0.082\n",
      "\n",
      "Average Validation Accuracy: 0.817\n",
      "*##########################################\n",
      " For SVM Kernel: poly\n",
      " Degree:3 \n",
      " Learning rate : 0.1\n",
      "----------------\n",
      "For the Fold:  1\n",
      "Validation Recall: 0.041\n",
      "Validation Precision: 0.500\n",
      "Validation Accuracy: 0.832\n",
      "----------------\n",
      "For the Fold:  2\n",
      "Validation Recall: 0.041\n",
      "Validation Precision: 0.333\n",
      "Validation Accuracy: 0.825\n",
      "----------------\n",
      "For the Fold:  3\n",
      "Validation Recall: 0.042\n",
      "Validation Precision: 0.286\n",
      "Validation Accuracy: 0.825\n",
      "*****************\n",
      "Average Validation Precision: 0.373\n",
      "\n",
      "Average Validation Recall: 0.041\n",
      "\n",
      "Average Validation Accuracy: 0.827\n",
      "*##########################################\n",
      " For SVM Kernel: poly\n",
      " Degree:4 \n",
      " Learning rate : 0.1\n",
      "----------------\n",
      "For the Fold:  1\n",
      "Validation Recall: 0.041\n",
      "Validation Precision: 0.667\n",
      "Validation Accuracy: 0.835\n",
      "----------------\n",
      "For the Fold:  2\n",
      "Validation Recall: 0.041\n",
      "Validation Precision: 0.400\n",
      "Validation Accuracy: 0.828\n",
      "----------------\n",
      "For the Fold:  3\n",
      "Validation Recall: 0.021\n",
      "Validation Precision: 0.200\n",
      "Validation Accuracy: 0.825\n",
      "*****************\n",
      "Average Validation Precision: 0.422\n",
      "\n",
      "Average Validation Recall: 0.034\n",
      "\n",
      "Average Validation Accuracy: 0.829\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1      \n",
    "kernels = ['rbf', 'poly']\n",
    "params = {'rbf': [0.1, 1, 10], 'poly': [2,3,4]}\n",
    "for kernel in kernels:\n",
    "    for p in params[kernel]:\n",
    "        if(kernel=='poly'):\n",
    "            print(f\"*##########################################\\n For SVM Kernel: {kernel}\\n Degree:{p} \\n Learning rate : {lr}\")  \n",
    "        else:\n",
    "            print(f\"*##########################################\\n For SVM Kernel: {kernel}\\n Sigma:{p} \\n Learning rate : {lr}\")  \n",
    "        Avg_precision, Avg_recall, Avg_accuracy = three_fold_cross_validation([[1,2,3,4,5,6], [1,2,3,7,8,9], [4,5,6,7,8,9]], [[7,8,9], [4,5,6], [1,2,3]], lr, kernel,p)\n",
    "        print(f\"*****************\\nAverage Validation Precision: {Avg_precision:.3f}\")\n",
    "        print(f\"\\nAverage Validation Recall: {Avg_recall:.3f}\")\n",
    "        print(f\"\\nAverage Validation Accuracy: {Avg_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a895f9",
   "metadata": {},
   "source": [
    "### GridSearch using 3-fold Cross Validation:\n",
    "\n",
    "The following are the values of the Cross Validation search, using only top 10 features that has the highest Information Gain,\n",
    "| RBF Kernel |   $\\sigma$  = 0.1    | $\\sigma$ = 1 |  $\\sigma$ = 10 | \n",
    "| :----------------    | :------: | ----: | ----: |\n",
    "|    Average Precision |   0.075    |  0.128   | 0.157 | \n",
    "| Average Recall      |   0.055  | 0.178 | 0.542|\n",
    "| Average Accuracy       |   0.730   | 0.660 | 0.436 |\n",
    "\n",
    "| Polynomial Kernel |   Degree = 2   | Degree = 3   |  Degree = 4   | \n",
    "| :----------------    | :------: | ----: |  ----:  |\n",
    "|Average Precision       |   0.332   | 0.373 | **0.422** |\n",
    "| Average Recall       |   0.082   | **0.041** | 0.034 |\n",
    "| Average Accuracy     |   0.817   | 0.827 | **0.829** |\n",
    "\n",
    "\n",
    "##### HyperParameters (Final Select): \n",
    "Polynomial Kernel with degree 4 performs better than all other hyperparameters since it gave better precision and accuracy for these values. Now, train the model with entire train dataset with the parameters found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf8f0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVM_poly(degree = 4)\n",
    "clf.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dae9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be23b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True Positives, True Negatives]: [3, 241]\n",
      "[False Positives, False Negatives]: [1, 46]\n",
      "Accuracy: 0.838\n",
      "Spam Precision: 0.750\n",
      "Spam Recall: 0.061\n",
      "*****************\n",
      " Confusion matrix:\n",
      "[[241   1]\n",
      " [ 46   3]]\n"
     ]
    }
   ],
   "source": [
    "predicted = np.where(predicted_labels == -1, 0, 1)\n",
    "pm = Performance_metrics(Y_test, predicted)\n",
    "pm.Print_Scores()\n",
    "print(\"*****************\\n Confusion matrix:\")\n",
    "print(confusion_matrix(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487120a",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "#### Clearly for only 10 extracted features, SVM classifier has a precision of 0.75 on test dataset and an accuracy of 0.84 on test dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
