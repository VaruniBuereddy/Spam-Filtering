{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b31b42c",
   "metadata": {},
   "source": [
    "# EL-GY-9133 Machine Learning for Cyber-Security\n",
    "\n",
    "## Lab 2: E-mail Spam Filtering\n",
    "\n",
    "#### Name: Varuni Buereddy\n",
    "#### Net-ID: vb2386\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1a625",
   "metadata": {},
   "source": [
    "### Overview\n",
    "In this lab, you will design an e-mail spam filter using a Naïve Bayes and SVM based classification on the ling-spam dataset. You will explore the impact of feature selection and compare the performance of different variants of an NB classifier and also implement your own SVM based classifier. (Note: You may use the scikitt learn classifiers to only compare the accuracy of their model to yours).\n",
    "\n",
    "### Dataset\n",
    "The ling-spam corpus contains e-mails from the Linguist mailing list categorized as either legitimate or spam emails. The corpus is divided into four sub-folders that contain the same emails that are pre-processed with/without lemmatization and with/without stop-word removal. The e-mails in each sub-folder partitioned into 10 \"folds.\"\n",
    "In this lab, we will use the first 9 folds from the ling-spam corpus as training data, and the 10th fold as test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1486d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157dbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = './lingspam_public/lemm_stop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cf68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfolder = os.listdir(path_to_dataset)\n",
    "trainfolder.remove('part10')\n",
    "testfolder = 'part10'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "462cad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading from folder\n",
    "\n",
    "def load_from_folder(folder, email_texts, labels):\n",
    "    folder = os.path.join(path_to_dataset,folder)\n",
    "    files = [os.path.join(folder,f) for f in os.listdir(folder)]\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            for i,line in enumerate(f):\n",
    "                if(i==2): \n",
    "                    email_texts.append(line)\n",
    "        if(file.startswith(folder+'/spmsg')):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0337e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************Training dataset:**************\n",
      "Number of Spam Emails: 432\n",
      "Number of Non-Spam Emails: 2170\n",
      "************Test dataset:**************\n",
      "Number of Spam Emails: 49\n",
      "Number of Non-Spam Emails: 242\n"
     ]
    }
   ],
   "source": [
    "train_emails = []\n",
    "train_labels = []\n",
    "test_emails = []\n",
    "test_labels = []\n",
    "\n",
    "for folder in trainfolder:\n",
    "    load_from_folder(folder, train_emails, train_labels)\n",
    "    \n",
    "load_from_folder(testfolder, test_emails, test_labels)\n",
    "\n",
    "spam_train_mails = sum(train_labels)\n",
    "spam_test_mails = sum(test_labels)\n",
    "print(\"************Training dataset:**************\")\n",
    "print(f\"Number of Spam Emails: {sum(train_labels)}\")\n",
    "print(f\"Number of Non-Spam Emails: {len(train_labels)-sum(train_labels)}\")\n",
    "\n",
    "print(\"************Test dataset:**************\")\n",
    "print(f\"Number of Spam Emails: {sum(test_labels)}\")\n",
    "print(f\"Number of Non-Spam Emails: {len(test_labels)-sum(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b01ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "def remove_punctuation(test_str):\n",
    "    result = ''.join(filter(lambda x: x.isalpha() or x.isdigit() or x.isspace(), test_str))\n",
    "    return result\n",
    "\n",
    "def get_features(email):\n",
    "    text = remove_punctuation(email)\n",
    "    return set([token for token in text.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b356b7cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class BernoulliNBTextClassifier():\n",
    "    def __init__(self):\n",
    "        self._log_priors = None\n",
    "        self.likelihood = None\n",
    "        self.features = None\n",
    "    \n",
    "    def train(self, emails, labels):\n",
    "        label_counts = Counter(labels)\n",
    "        N = float(sum(label_counts.values()))\n",
    "        self._log_priors = {k: np.log(v/N) for k, v in label_counts.items()}\n",
    "        X = [set(get_features(mail)) for mail in emails]\n",
    "        self.features = set([f for features in X for f in features])\n",
    "        self.likelihood = {l: {f: 0. for f in self.features} for l in self._log_priors}\n",
    "        \n",
    "        for x, l in zip(X, labels):\n",
    "            for f in x:\n",
    "                self.likelihood[l][f] += 1.\n",
    "\n",
    "        # Now, compute log probs\n",
    "        for l in self.likelihood:\n",
    "            N = label_counts[l]\n",
    "            self.likelihood[l] = {f: (v + 1.) / (N + 2.) for f, v in self.likelihood[l].items()}\n",
    "    \n",
    "    \n",
    "    def predict(self, text):\n",
    "        # Extract features\n",
    "        x = get_features(text)\n",
    "\n",
    "        pred_class = None\n",
    "        max_ = float(\"-inf\")\n",
    "\n",
    "        for l in self._log_priors:\n",
    "            log_sum = self._log_priors[l]\n",
    "            for f in self.features:\n",
    "                prob = self.likelihood[l][f]\n",
    "                log_sum += np.log(prob if f in x else 1. - prob)\n",
    "            if log_sum > max_:\n",
    "                max_ = log_sum\n",
    "                pred_class = l\n",
    "\n",
    "        return pred_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68fa4243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNBTextClassifier()\n",
    "nb.train(train_emails, train_labels)\n",
    "\n",
    "print('Testing model...')\n",
    "f = lambda doc, l: 1. if nb.predict(doc) != l else 0.\n",
    "num_missed = sum([f(doc, l) for doc, l in zip(test_emails, test_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ddb4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of 10.997% (32/291)\n"
     ]
    }
   ],
   "source": [
    "N = len(test_labels) * 1.\n",
    "error_rate = round(100. * (num_missed / N), 3)\n",
    "\n",
    "print('Error rate of {0}% ({1}/{2})'.format(error_rate, int(num_missed), int(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "259f66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_spam_count = []\n",
    "X_train_ham_count = []\n",
    "for i in range(len(processed_train)):\n",
    "    if train_labels[i]==1:\n",
    "        X_train_spam_count.append(X_train_count[i])\n",
    "    \n",
    "    else:\n",
    "        X_train_ham_count.append(X_train_count[i])\n",
    "\n",
    "n = np.sum(np.array(X_train_spam_count), axis = 0)\n",
    "m = np.sum(np.array(X_train_ham_count), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03572c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae014bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info(feature, feature_matrix, N, N_spam):\n",
    "    \"\"\"\n",
    "    feature - each term in the vocabulary created\n",
    "    feature_matrix - \n",
    "    N - Number of train_emails\n",
    "    \"\"\"\n",
    "    \n",
    "    N11 = feature_matrix[0][feature]\n",
    "    N10 = feature_matrix[1][feature]\n",
    "    N01 = (N_spam - N11)\n",
    "    N00 = N - (N11+N01+N10)\n",
    "    N1dot = N11+N10\n",
    "    Ndot1 = N_spam\n",
    "    N0dot = N01+N00\n",
    "    Ndot0 = N-N_spam\n",
    "    keys = [N11, N10, N01, N00]\n",
    "    values = [N1dot*Ndot1, N1dot*Ndot0, N0dot*Ndot1, N0dot*Ndot0]\n",
    "    mi = 0\n",
    "    for i in range(4):\n",
    "        if keys[i]==0:\n",
    "            mi+=0\n",
    "        else:\n",
    "            mi+= (keys[i]/N)*np.log2(keys[i]*N/values[i])\n",
    "    return mi \n",
    "\n",
    "IG = []\n",
    "for i in range(len(vocab)):\n",
    "    IG.append(mutual_info(i, feature_matrix, len(train_labels), spam_train_mails))\n",
    "    \n",
    "sorted_index = np.argsort(np.array(IG))[::-1][:10000]\n",
    "features = [vocab[s] for s in sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba7a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## X, Y\n",
    "def classifier(X, feature_matrix, features, N, N_spam):\n",
    "    Px_spam = 1\n",
    "    Px_legit = 1\n",
    "    for i in range(len(features)):\n",
    "        #print(feature_matrix[0][i]+1)\n",
    "        p_is = (feature_matrix[0][i]+1)/(N_spam+2)\n",
    "        p_il = (feature_matrix[1][i]+1)/(N-N_spam+2)\n",
    "        if features[i] in X:\n",
    "            Px_spam = Px_spam*p_is\n",
    "            Px_legit = Px_legit*p_il\n",
    "            \n",
    "        else:\n",
    "            Px_spam = Px_spam*(1-p_is)\n",
    "            Px_legit = Px_legit*(1-p_il)\n",
    "            \n",
    "    return Px_spam, (1-Px_spam)#Px_legit #(1-Px_spam)#Px_legit\n",
    "\n",
    "\n",
    "Px_spam, Px_legit = classifier(remove_punctuation(test_emails[0]).split(' '), feature_matrix, features, len(train_labels), spam_train_mails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b163ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2183112842324327e-173\n",
      "7.283366435851722e-182\n",
      "2.0227151829105156e-174\n",
      "0.9999999699703778\n"
     ]
    }
   ],
   "source": [
    "P_spam = spam_train_mails/len(train_labels)\n",
    "P_legit = 1-P_spam\n",
    "Px = P_spam*Px_spam + P_legit*Px_legit\n",
    "\n",
    "Pspam_x = P_spam*Px_spam/Px\n",
    "\n",
    "print(Px_spam)\n",
    "print(Px_legit)\n",
    "print(Px)\n",
    "print(Pspam_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecd64de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train_count, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d144f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_email_count = v.transform(processed_test)\n",
    "test_pred = model.predict(test_email_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f271718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       242\n",
      "           1       1.00      0.35      0.52        49\n",
      "\n",
      "    accuracy                           0.89       291\n",
      "   macro avg       0.94      0.67      0.73       291\n",
      "weighted avg       0.90      0.89      0.87       291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b94fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "s = ['The dog  is in the   well ', 'The food is  delicious', 'the cat']\n",
    "\n",
    "v = CountVectorizer(binary=True)\n",
    "vec = v.fit_transform(s)\n",
    "vocab = v.vocabulary_\n",
    "vocab = dict((v,k) for k,v in vocab.items())\n",
    "\n",
    "print(vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
